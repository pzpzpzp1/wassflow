{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn  import functional as F \n",
    "from torch.autograd import Variable\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from torch.distributions import MultivariateNormal\n",
    "use_cuda = torch.cuda.is_available()\n",
    "from geomloss import SamplesLoss\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundingBox():\n",
    "    ## use like:\n",
    "    # BB = BoundingBox(z_target);\n",
    "    # smps = BB.sampleuniform(t_N = 30, x_N = 10, y_N = 11, z_N=12, bbscale = 1.1);\n",
    "    # smps = BB.samplerandom(N = 10000, bbscale = 1.1);\n",
    "    \n",
    "    def __init__(self, z_target_full):\n",
    "        self.T = z_target_full.shape[0]; \n",
    "        self.dim = z_target_full.shape[2];\n",
    "        \n",
    "        # min corner, max corner, center\n",
    "        self.mic = z_target_full.reshape(-1,self.dim).min(0)[0];\n",
    "        self.mac = z_target_full.reshape(-1,self.dim).max(0)[0]; \n",
    "        self.C = (self.mic+self.mac)/2; \n",
    "        \n",
    "    def extendedBB(self, bbscale):\n",
    "        # extended bounding box.\n",
    "        emic = (self.mic-self.C)*bbscale+self.C; \n",
    "        emac = (self.mac-self.C)*bbscale+self.C; \n",
    "        return emic, emac;\n",
    "        \n",
    "    def sampleuniform(self, t_N = 30, x_N = 10, y_N = 11, z_N = 12, bbscale = 1.1):\n",
    "        [eLL,eTR] = self.extendedBB(bbscale);\n",
    "        \n",
    "        tspace = torch.linspace(1, self.T, t_N);\n",
    "        xspace = torch.linspace(eLL[0], eTR[0], x_N);\n",
    "        yspace = torch.linspace(eLL[1], eTR[1], y_N);\n",
    "        if self.dim == 3:\n",
    "            zspace = torch.linspace(eLL[2], eTR[2], z_N);\n",
    "            xgrid,ygrid,zgrid,tgrid=torch.meshgrid(xspace,yspace,zspace,tspace);\n",
    "            z_sample = torch.transpose(torch.reshape(torch.stack([tgrid,xgrid,ygrid,zgrid]),(4,-1)),0,1).to(device);\n",
    "        else:\n",
    "            xgrid,ygrid,tgrid=torch.meshgrid(xspace,yspace,tspace);\n",
    "            z_sample = torch.transpose(torch.reshape(torch.stack([tgrid,xgrid,ygrid]),(3,-1)),0,1).to(device);\n",
    "        \n",
    "        return z_sample.to(device)\n",
    "    \n",
    "    def samplerandom(self, N = 10000, bbscale = 1.1):\n",
    "        [eLL,eTR] = self.extendedBB(bbscale);\n",
    "        dT = torch.Tensor([self.T-1]).to(device);\n",
    "        TC = torch.Tensor([(self.T+1.0)/2.0]).to(device);\n",
    "        \n",
    "        z_sample = torch.rand(N, self.dim + 1).to(device)-0.5;\n",
    "        deltx = torch.cat((dT,eTR-eLL))\n",
    "        z_sample = deltx*z_sample + torch.cat((TC,self.C));\n",
    "\n",
    "        return z_sample\n",
    "    \n",
    "# fourier features mapping\n",
    "class InputMapping(nn.Module):\n",
    "    def __init__(self, d_in, n_freq, sigma=.4):\n",
    "        super().__init__()\n",
    "        self.B = nn.Parameter(torch.randn(n_freq, d_in) * sigma, requires_grad=False).to(device)\n",
    "        self.d_in = d_in;\n",
    "        self.n_freq = n_freq;\n",
    "        self.d_out = n_freq * 2 + d_in - 1;\n",
    "    def forward(self, xi):\n",
    "        # x = (xi/(2*np.pi)) @ self.B.T\n",
    "        x = (2*np.pi*xi) @ self.B.T\n",
    "        # pdb.set_trace()\n",
    "        return torch.cat([torch.sin(x), torch.cos(x), xi[:,[1, 2]]], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEfunc(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates time derivatives.\n",
    "\n",
    "    torchdiffeq requires this to be a torch.nn.Module.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ODEfunc, self).__init__()\n",
    "        # Define network layers.\n",
    "        n_freq = 15; # frequencies to sample spacetime in.\n",
    "        Z_DIM = 2; # dimension of vector field.\n",
    "        imap = InputMapping(Z_DIM+1, n_freq);\n",
    "        self.f = nn.Sequential(imap,\n",
    "                       nn.Linear(imap.d_out, 64),\n",
    "                       nn.Softplus(),\n",
    "                       nn.Linear(64, 64),\n",
    "                       nn.Softplus(),\n",
    "                       nn.Linear(64, Z_DIM));\n",
    "\n",
    "    def get_z_dot(self, t, z):\n",
    "        \"\"\"z_dot is parameterized by a NN: z_dot = NN(t, z(t))\"\"\"\n",
    "        if t.dim()==0:\n",
    "            t = t.expand(z.shape[0],1);\n",
    "        else:\n",
    "            t = t.reshape(z.shape[0],1);\n",
    "            \n",
    "        tz = torch.cat((t,z),1);\n",
    "        # pdb.set_trace()\n",
    "        z_dot = self.f(tz)\n",
    "        return z_dot\n",
    "    \n",
    "#     def __init__(self, hidden_dims=(64,64)):\n",
    "#         super(ODEfunc, self).__init__()\n",
    "#         # Define network layers.\n",
    "#         n_freq = 15; # frequencies to sample spacetime in.\n",
    "#         Z_DIM = 2; # dimension of vector field.\n",
    "#         imap = InputMapping(3, n_freq);\n",
    "#         dim_list = [imap.d_out] + list(hidden_dims) + [Z_DIM]\n",
    "#         layers = []\n",
    "#         layers.append(imap);\n",
    "#         for i in range(len(dim_list)-1):\n",
    "#             layers.append(nn.Linear(dim_list[i]+1, dim_list[i+1]))\n",
    "#         self.layers = nn.ModuleList(layers)\n",
    "\n",
    "#     def get_z_dot(self, t, z):\n",
    "#         # pdb.set_trace()\n",
    "#         \"\"\"z_dot is parameterized by a NN: z_dot = NN(t, z(t))\"\"\"\n",
    "#         z_dot = z;\n",
    "#         for l, layer in enumerate(self.layers):\n",
    "#             # Concatenate t at each layer.\n",
    "#             tz_cat = torch.cat((t.expand(z.shape[0],1), z_dot), dim=1)\n",
    "#             z_dot = layer(tz_cat) #add time t into first spot\n",
    "#             # pdb.set_trace()\n",
    "#             if l < len(self.layers) - 1 and not l == 0:\n",
    "#                 #pdb.set_trace()\n",
    "#                 z_dot = F.softplus(z_dot)\n",
    "#         return z_dot\n",
    "\n",
    "    # d z_dot d z. assuming zdot was computed from z. otherwise output is just 0.\n",
    "    def getJacobians(self, t, z):\n",
    "        batchsize = z.shape[0]\n",
    "\n",
    "        with torch.set_grad_enabled(True):            \n",
    "            z.requires_grad_(True)\n",
    "            t.requires_grad_(True)\n",
    "            z_dot = self.get_z_dot(t, z)\n",
    "            \n",
    "            # compute jacobian of velocity field. [N,2,2]\n",
    "            # inputs z_dot.sum() because each z_dot only depends on one z. no cross derivatives. this batches the grad.\n",
    "            dim = z.shape[1];\n",
    "            jacobians = torch.zeros([batchsize,dim,dim], dtype=z.dtype, device=z.device);\n",
    "            for i in range(z.shape[1]):\n",
    "                 jacobians[:,i,:] = torch.autograd.grad( z_dot[:, i].sum(), z, create_graph=True)[0]\n",
    "        return z_dot, jacobians\n",
    "    \n",
    "    def forward(self, t, state):\n",
    "        \"\"\"\n",
    "        Calculate the time derivative of z and divergence.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        t : torch.Tensor\n",
    "            time\n",
    "        state : torch.Tensor\n",
    "            Contains z\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        z_dot : torch.Tensor\n",
    "            Time derivative of z.\n",
    "        negative_divergence : torch.Tensor\n",
    "            Time derivative of the log determinant of the Jacobian.\n",
    "        \"\"\"\n",
    "        z = state\n",
    "        batchsize = z.shape[0]\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            z.requires_grad_(True)\n",
    "            t.requires_grad_(True)\n",
    "\n",
    "            # Calculate the time derivative of z. \n",
    "            # This is f(z(t), t; \\theta) in Eq. 4.\n",
    "            z_dot = self.get_z_dot(t, z)\n",
    "            \n",
    "        return z_dot\n",
    "\n",
    "class FfjordModel(torch.nn.Module):\n",
    "    \"\"\"Continuous noramlizing flow model.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FfjordModel, self).__init__()\n",
    "        self.time_deriv_func = ODEfunc()\n",
    "\n",
    "    def save_state(self, fn='state.tar'):\n",
    "        \"\"\"Save model state.\"\"\"\n",
    "        torch.save(self.state_dict(), fn)\n",
    "\n",
    "    def load_state(self, fn='state.tar'):\n",
    "        \"\"\"Load model state.\"\"\"\n",
    "        self.load_state_dict(torch.load(fn))\n",
    "\n",
    "\n",
    "    def forward(self, z, integration_times=None, reverse=False):\n",
    "        \"\"\"\n",
    "        Implementation of Eq. 4.\n",
    "        We want to integrate both f and the trace term. During training, we\n",
    "        integrate from t_1 (data distribution) to t_0 (base distibution).\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : torch.Tensor\n",
    "            Samples.\n",
    "        integration_times : torch.Tensor\n",
    "            Which times to evaluate at.\n",
    "        reverse : bool, optional\n",
    "            Whether to reverse the integration times.\n",
    "        Returns\n",
    "        -------\n",
    "        z : torch.Tensor\n",
    "            Updated samples.\n",
    "        \"\"\"\n",
    "        if integration_times is None:\n",
    "            integration_times = torch.tensor([0.0, 1.0]).to(z)\n",
    "        if reverse:\n",
    "            integration_times = _flip(integration_times, 0)\n",
    "        #print('integration_times',integration_times)\n",
    "        # Integrate. This is the call to torchdiffeq.\n",
    "        \n",
    "        state = odeint(\n",
    "            self.time_deriv_func, # Calculates time derivatives.\n",
    "            z, # Values to update.\n",
    "            integration_times, # When to evaluate.\n",
    "            method='dopri5', # Runge-Kutta\n",
    "            atol=1e-5, # Error tolerance\n",
    "            rtol=2e-5, # Error tolerance\n",
    "        )\n",
    "        \n",
    "        z = state\n",
    "        return z\n",
    "    \n",
    "def _flip(x, dim):\n",
    "    indices = [slice(None)] * x.dim()\n",
    "    indices[dim] = torch.arange(x.size(dim) - 1, -1, -1, dtype=torch.long,             device=x.device)\n",
    "    return x[tuple(indices)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_image(n=10000):\n",
    "    \"\"\"Make an X shape.\"\"\"\n",
    "    points = np.zeros((n,2))\n",
    "    points[:n//2,0] = np.linspace(-1,1,n//2)\n",
    "    points[:n//2,1] = np.linspace(1,-1,n//2)\n",
    "    points[n//2:,0] = np.linspace(1,-1,n//2)\n",
    "    points[n//2:,1] = np.linspace(1,-1,n//2)\n",
    "    np.random.seed(42)\n",
    "    noise = np.clip(np.random.normal(scale=0.1, size=points.shape),-0.2,0.2)\n",
    "    np.random.seed(None)\n",
    "    points += noise\n",
    "    img, _ = np.histogramdd(points, bins=40, range=[[-1.5,1.5],[-1.5,1.5]])\n",
    "    return img\n",
    "\n",
    "\n",
    "class ImageDataset():\n",
    "    \"\"\"Sample from a distribution defined by an image.\"\"\"\n",
    "\n",
    "    def __init__(self, img, MAX_VAL=4.0, thresh=0):\n",
    "        img[img<thresh]=0; # threshold to cut empty region of image\n",
    "        \n",
    "        h, w = img.shape\n",
    "        xx = np.linspace(-MAX_VAL, MAX_VAL, w)\n",
    "        yy = np.linspace(-MAX_VAL, MAX_VAL, h)\n",
    "        xx, yy = np.meshgrid(xx, yy)\n",
    "        xx = xx.reshape(-1, 1)\n",
    "        yy = yy.reshape(-1, 1)\n",
    "        self.means = np.concatenate([xx, yy], 1)\n",
    "        self.probs = img.reshape(-1); \n",
    "        self.probs /= self.probs.sum();\n",
    "        self.noise_std = np.array([MAX_VAL/w, MAX_VAL/h])\n",
    "\n",
    "    def sample(self, batch_size=512):\n",
    "        inds = np.random.choice(int(self.probs.shape[0]), int(batch_size), p=self.probs)\n",
    "        m = self.means[inds]\n",
    "        samples = np.random.randn(*m.shape) * self.noise_std + m\n",
    "        return torch.from_numpy(samples).type(torch.FloatTensor)\n",
    "    \n",
    "def import_img(file):\n",
    "    \"\"\"\n",
    "    file : str\n",
    "        filename for an rgba image\n",
    "    Returns\n",
    "    gimg : 2D array\n",
    "        greyscale image\n",
    "    \"\"\"\n",
    "    img = plt.imread(file)\n",
    "    rgb_weights = [0.2989, 0.5870, 0.1140]\n",
    "    gimg = np.dot(img[...,:3], rgb_weights)\n",
    "    return gimg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = ['red','orange','magenta','cyan']\n",
    "colors = ['green','green','green','green']\n",
    "\n",
    "\n",
    "import os\n",
    "def save_trajectory(model,z_target, my_loss, savedir='imgs', nsteps=20, memory=0.01, n=1000, reverse=False):\n",
    "    \"\"\"\n",
    "    Plot the dynamics of the learned ODE.\n",
    "    Saves images to `savedir`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : FfjordModel\n",
    "        Model defining the dynamics.\n",
    "    z_target : torch.Tensor \n",
    "        Tensor of shape (T,n,d) where T is the number of timesteps\n",
    "    myloss : str\n",
    "        Name of loss used to train the model\n",
    "    savedir : str, optional\n",
    "        Where to save output.\n",
    "    ntimes : int, optional\n",
    "        Number of timesteps to visualize.\n",
    "    memory : float\n",
    "        Controls how finely the density grid is sampled.\n",
    "    n : int, optional\n",
    "        Number of samples to visualize.\n",
    "    \"\"\"\n",
    "    \n",
    "    if reverse: \n",
    "        my_loss+='_neg';\n",
    "    \n",
    "    final_dir = savedir+'/'+my_loss\n",
    "    if not os.path.exists(final_dir):\n",
    "        os.makedirs(final_dir)\n",
    "    \n",
    "    T = z_target.shape[0]\n",
    "    if reverse:\n",
    "        x_traj = model(z_target[T-1,:,:], integration_times= torch.linspace(0,T-1,nsteps).to(device), reverse=reverse).cpu().detach(); \n",
    "    else:\n",
    "        x_traj = model(z_target[0,:,:], integration_times= torch.linspace(0,T-1,nsteps).to(device), reverse=reverse).cpu().detach()\n",
    "    \n",
    "    x_traj = x_traj.detach().numpy()\n",
    "\n",
    "    for i in range(nsteps):\n",
    "        plt.scatter(x_traj[i,:,0], x_traj[i,:,1], s=10, alpha=.5, linewidths=0, c='blue', edgecolors='black')\n",
    "        for t in range(T):\n",
    "            plt.scatter(z_target.cpu().detach().numpy()[t,:,0], z_target.cpu().detach().numpy()[t,:,1], s=10, alpha=.5, linewidths=0, c=colors[t], edgecolors='black')\n",
    "        plt.axis('equal')\n",
    "        plt.savefig(os.path.join(final_dir, f\"viz-{i:05d}.jpg\"))\n",
    "        plt.clf()\n",
    "        \n",
    "#         plt.scatter(x_traj[i,:,0], x_traj[i,:,1], s=2.3, alpha=1, linewidths=0.1, c='blue')\n",
    "#         plt.scatter(dat.detach().numpy()[:,0],dat.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='green')\n",
    "#         plt.scatter(dat2.detach().numpy()[:,0],dat2.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='green')\n",
    "#         plt.scatter(dat3.detach().numpy()[:,0],dat3.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='green')\n",
    "#         plt.savefig(os.path.join(final_dir, f\"viz-{i:05d}.jpg\"))\n",
    "#         plt.clf()\n",
    "\n",
    "    trajectory_to_video(my_loss, savedir, mp4_fn='transform.mp4')\n",
    "\n",
    "\n",
    "def trajectory_to_video(my_loss,savedir='imgs', mp4_fn='transform.mp4'):\n",
    "    \"\"\"Save the images written by `save_trajectory` as an mp4.\"\"\"\n",
    "    import subprocess\n",
    "    final_dir = savedir+'/'+my_loss\n",
    "    img_fns = os.path.join(final_dir, 'viz-%05d.jpg')\n",
    "    video_fn = os.path.join(final_dir, mp4_fn)\n",
    "    bashCommand = 'ffmpeg -y -i {} {}'.format(img_fns, video_fn)\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def learn_trajectory(z_target_full, my_loss, n_iters = 10, n_subsample = 100, model=FfjordModel(), save=False):\n",
    "    \n",
    "    \"\"\"\n",
    "        Learns a trajectory between multiple timesteps contained in z_target\n",
    "        ----------\n",
    "        z_target : torch.Tensor \n",
    "            Tensor of shape (T,n,d) where T is the number of timesteps\n",
    "        my_loss : str\n",
    "            Data fidelity loss, either 'sinkhorn_large_reg', 'sinkhorn_small_reg' or 'energy_distance'\n",
    "        Returns\n",
    "        -------\n",
    "        model : \n",
    "            NN representing the vector field\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "    if my_loss == 'sinkhorn_large_reg':\n",
    "        my_loss_f = SamplesLoss(\"sinkhorn\", p=2, blur=0.01)\n",
    "    elif my_loss == 'sinkhorn_small_reg':\n",
    "        my_loss_f = SamplesLoss(\"sinkhorn\", p=2, blur=1)\n",
    "    else:\n",
    "        my_loss_f = SamplesLoss(\"energy\") # Energy Distance\n",
    "\n",
    "\n",
    "#     model = FfjordModel(); \n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-5)\n",
    "    T = z_target_full.shape[0];\n",
    "\n",
    "#     # get spacetime bounding box and spacetime sample grid\n",
    "    BB = BoundingBox(z_target_full);\n",
    "    \n",
    "#     t_N = 30; x_N = 10; bbscale = 1.1;\n",
    "#     t_sample = torch.linspace(1, T, t_N).to(device);\n",
    "#     LL = z_target_full.min(0)[0].min(0)[0]; TR = z_target_full.max(0)[0].max(0)[0]; C = (LL+TR)/2; # lower left, top right, center\n",
    "#     eLL = (LL-C)*1.1+C; eTR = (TR-C)*1.1+C; # extended bounding box.\n",
    "#     xspace = torch.linspace(eLL[0],eTR[0],x_N); yspace = torch.linspace(eLL[1],eTR[1],x_N);\n",
    "#     xgrid,ygrid=torch.meshgrid(xspace,yspace);\n",
    "#     z_sample = torch.transpose(torch.reshape(torch.stack([xgrid,ygrid]),(2,-1)),0,1).to(device);\n",
    "    \n",
    "    losses = []\n",
    "    start = time.time()\n",
    "    print('training with %s'%my_loss)\n",
    "    start0 = time.time()\n",
    "    for batch in range(n_iters):        \n",
    "        # get spacetime bounding box and spacetime sample grid\n",
    "        \n",
    "        if (batch % 10 == 1):\n",
    "            start = time.time()\n",
    "\n",
    "        # subsample z_target_full to z_target for loss computation\n",
    "        fullshape = z_target_full.shape; # [T, n_samples, d]\n",
    "        z_target = torch.zeros([fullshape[0], n_subsample, fullshape[2]]).to(z_target_full)\n",
    "        for i in range(fullshape[0]):\n",
    "            # pdb.set_trace()\n",
    "            subsample_inds = torch.randint(0, high=fullshape[1], size=[n_subsample]);\n",
    "            z_target[i,:,:] = z_target_full[i,subsample_inds,:]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        print('TIMER ITER START ==============')\n",
    "        ## FORWARD fitting loss\n",
    "        # integrate ODE forward in time\n",
    "        cpt = time.time();\n",
    "        z_t = model(z_target[0,:,:], integration_times = torch.linspace(0,T-1,T).to(device))\n",
    "        fitloss = torch.tensor(0.).to(device)\n",
    "        for t in range(1,T):\n",
    "            fitloss += my_loss_f(z_target[t,:,:], z_t[t,:,:])\n",
    "        print('forwards time ',time.time()-cpt)\n",
    "        \n",
    "        ## BACKWARDS fitting loss\n",
    "        # integrate ODE backward in time from last keyframe\n",
    "        cpt = time.time();\n",
    "        z_t_b = model(z_target[T-1,:,:], integration_times = torch.linspace(0,T-1,T).to(device), reverse=True)\n",
    "        fitlossB = torch.tensor(0.).to(device)\n",
    "        for t in range(1,T):\n",
    "            fitlossB += my_loss_f(z_target[(T-1)-t,:,:], z_t_b[t,:,:])\n",
    "        print('backwards time ',time.time()-cpt)\n",
    "        \n",
    "        loss = 1*fitloss + 1*fitlossB;\n",
    "        \n",
    "#         # VELOCITY REGULARIZERS loss\n",
    "#         z_sample = BB.samplerandom(N = 3000, bbscale = 1.1);\n",
    "#         z_dots, zt_jacs = model.time_deriv_func.getJacobians(z_sample[:,0], z_sample[:,1:]);\n",
    "#         # divergence squared\n",
    "#         div2loss = (zt_jacs[:,0,0]+zt_jacs[:,1,1])**2\n",
    "#         # square norm of curl\n",
    "#         curl2loss = (zt_jacs[:,0,1]-zt_jacs[:,1,0])**2\n",
    "#         # rigid motion: x(t) -> e^[wt] x0 + kt. v = x_dot = [w]x0+k; dvdx = [w]. ==> skew symmetric velocity gradient is rigid.\n",
    "#         rigid2loss = ((zt_jacs[:,0,1]+zt_jacs[:,1,0])**2)/2 + (zt_jacs[:,0,0])**2 + (zt_jacs[:,1,1])**2 \n",
    "#         # kinetic energy loss\n",
    "#         KEloss = zt_jacs[:,0,0]**2 + zt_jacs[:,1,1]**2+zt_jacs[:,0,1]**2 + zt_jacs[:,1,0]**2\n",
    "            \n",
    "# #         # combine energies\n",
    "#         loss += 0*div2loss.sum() \\\n",
    "#                 + 0*curl2loss.sum() + 0*rigid2loss.sum() \\\n",
    "#                 + 0*KEloss.sum() # - 0*torch.clamp(curl2loss[range(0,t_N//5),:].sum(), max = 10**3)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        cpt = time.time()\n",
    "        loss.backward()\n",
    "        print('backpropagation time ',time.time()-cpt)\n",
    "        optimizer.step()\n",
    "        print('opt step time ',time.time()-cpt)\n",
    "        \n",
    "        if (batch % 10 == 0):\n",
    "            print('batch',batch,'loss',loss)\n",
    "            \n",
    "            plt.scatter(z_target.cpu().detach().numpy()[0,:,0], z_target.cpu().detach().numpy()[0,:,1], s=10, alpha=.5, linewidths=0, c='green', edgecolors='black')\n",
    "            for t in range(1,T):\n",
    "                plt.scatter(z_t_b.cpu().detach().numpy()[t,:,0], z_t_b.cpu().detach().numpy()[t,:,1], s=10, alpha=.5, linewidths=0, c='red', edgecolors='black')\n",
    "                plt.scatter(z_t.cpu().detach().numpy()[t,:,0], z_t.cpu().detach().numpy()[t,:,1], s=10, alpha=.5, linewidths=0, c='blue', edgecolors='black')\n",
    "                plt.scatter(z_target.cpu().detach().numpy()[t,:,0], z_target.cpu().detach().numpy()[t,:,1], s=10, alpha=.5, linewidths=0, c=colors[t], edgecolors='black')\n",
    "            plt.axis('equal')\n",
    "            plt.show()\n",
    "            \n",
    "            ptime = time.time()-start\n",
    "            print('time elapsed',ptime,'total time',time.time()-start0)\n",
    "            print('batch number',batch,'out of',n_iters)\n",
    "            \n",
    "            if save:\n",
    "                model.save_state(fn='models/state' + str(batch) + '_time_' + str(ptime) + '.tar')\n",
    "                \n",
    "            \n",
    "\n",
    "#             ## check garbage collected tensor list for increase in tensor sizes or number of objects.\n",
    "#             cc = 0;\n",
    "#             for obj in gc.get_objects():\n",
    "#                 try:\n",
    "#                     if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "#                         cc+=1;\n",
    "#                         print(type(obj), obj.size(), obj.grad_fn)\n",
    "#                 except:\n",
    "#                     pass\n",
    "#             print('nobjs ', cc);\n",
    "\n",
    "\n",
    "        fitloss.detach();\n",
    "        fitlossB.detach();\n",
    "        z_t.detach();\n",
    "        z_t_b.detach();\n",
    "        loss.detach();\n",
    "        del loss;\n",
    "        torch.cuda.empty_cache()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "caterpillar = 1-import_img('caterpillar.png'); caterpillar/=caterpillar.max();\n",
    "butterfly = 255-import_img('butterfly.jpg'); butterfly/=butterfly.max();\n",
    "dset1 = ImageDataset(img=caterpillar*1,thresh=.8); dset2 = ImageDataset(img=butterfly*1,thresh=.8)\n",
    "\n",
    "# n = 3000; dat1 = dset1.sample(n); dat2 = dset2.sample(n); dat3 = dset1.sample(n);\n",
    "# dat1*=-1; dat2*=-1; dat1[:,1]-=1; dat2[:,1]+=5; dat3*=-1;\n",
    "# dat3[:,0]+=8; dat3[:,1]+=6;\n",
    "\n",
    "n = 1000; dat1 = dset1.sample(n); dat2 = dset1.sample(n); dat3 = dset1.sample(n);\n",
    "dat1*=-1; dat2*=-1; dat1[:,1]-=1; dat2[:,1]+=5; dat3*=-1;\n",
    "dat3[:,0]+=8; dat3[:,1]+=5;\n",
    "\n",
    "plt.scatter(dat1.detach().numpy()[:,0],dat1.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='green')\n",
    "plt.scatter(dat2.detach().numpy()[:,0],dat2.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='red')\n",
    "plt.scatter(dat3.detach().numpy()[:,0],dat3.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='magenta')\n",
    "plt.axis('equal')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_tuple = (dat1,dat2,dat3)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "model = FfjordModel(); \n",
    "# model.load_state('models/seq_state420_time_31.615391731262207.tar');\n",
    "# model.load_state('models/state310_time_22.49951934814453.tar');\n",
    "for my_loss in ['sinkhorn_small_reg']:\n",
    "    %prun model = learn_trajectory(z_target, my_loss=my_loss,n_iters=320,n_subsample=100, model=model, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example with 3 timesteps\n",
    "dset = ImageDataset(img=make_image())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dat = dset.sample(512)\n",
    "dat2 = torch.add(dat,torch.tensor([10,-10]))\n",
    "dat3 = torch.add(dat,torch.tensor([20,0]))\n",
    "dat_tuple = (dat,dat2,dat3)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "\n",
    "# for my_loss in ['sinkhorn_large_reg','sinkhorn_small_reg']:\n",
    "for my_loss in ['sinkhorn_small_reg']:\n",
    "    model = learn_trajectory(z_target, my_loss=my_loss,n_iters=10,n_subsample=100)\n",
    "    save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "    trajectory_to_video(my_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with 2 timesteps\n",
    "dset = ImageDataset(img=make_image())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dat = dset.sample(512)\n",
    "dat2 = torch.add(dat,torch.tensor([10,-10]))\n",
    "\n",
    "dat_tuple = (dat,dat2)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "\n",
    "for my_loss in ['sinkhorn_large_reg','sinkhorn_small_reg','energy_dist']:\n",
    "    model = learn_trajectory(z_target, my_loss=my_loss,n_batch=1000)\n",
    "    save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "    trajectory_to_video(my_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trying other shapes\n",
    "\n",
    "square = np.zeros([20,20])\n",
    "square[6:14,:8] = 1\n",
    "\n",
    "two_square = np.zeros([20,20])\n",
    "two_square[:5,14:] = 1\n",
    "two_square[15:,14:] = 1\n",
    "\n",
    "\n",
    "annulus = import_img('annulus.png')\n",
    "circle = 255-import_img('circle.jpeg')\n",
    "\n",
    "dset = ImageDataset(img=square)\n",
    "dset1 = ImageDataset(img=two_square)\n",
    "\n",
    "n = 500\n",
    "dat = dset.sample(n)\n",
    "dat1 = dset1.sample(n)\n",
    "plt.scatter(dat.detach().numpy()[:,0],dat.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='green')\n",
    "plt.scatter(dat1.detach().numpy()[:,0],dat1.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='red')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make half moon dataset\n",
    "import sklearn.datasets\n",
    "\n",
    "moons, labels = sklearn.datasets.make_moons(n,noise=.1) #generates two half moons\n",
    "mask = (labels == 0)\n",
    "one_moon = moons[mask,:] # only keep one moon\n",
    "\n",
    "def rot_mat(theta0):\n",
    "    #computes rotation matrix of angle theta\n",
    "    return np.array([[np.cos(theta0),-np.sin(theta0)],[np.sin(theta0),np.cos(theta0)]])\n",
    "\n",
    "theta0 = np.pi/2\n",
    "theta1 = np.pi\n",
    "\n",
    "rot0 = rot_mat(theta0)\n",
    "rot1 = rot_mat(theta1)\n",
    "\n",
    "# apply rotation to the moon\n",
    "one_moon_rot0 = np.dot(one_moon,rot0)\n",
    "one_moon_rot1 = np.dot(one_moon,rot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize rotated moons\n",
    "\n",
    "plt.scatter(one_moon[:,0],one_moon[:,1], color='blue')\n",
    "plt.scatter(one_moon_rot0[:,0],one_moon_rot0[:,1], color='orange')\n",
    "plt.scatter(one_moon_rot1[:,0],one_moon_rot1[:,1], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with three timesteps\n",
    "\n",
    "dat = torch.tensor(one_moon,dtype=torch.float)\n",
    "dat0 = torch.tensor(one_moon_rot0,dtype=torch.float)\n",
    "dat1 = torch.tensor(one_moon_rot1,dtype=torch.float)\n",
    "\n",
    "dat_tuple = (dat,dat0,dat1)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for my_loss in ['sinkhorn_large_reg','sinkhorn_small_reg','energy_dist']:\n",
    "    model = learn_trajectory(z_target, my_loss=my_loss,n_batch=500)\n",
    "    save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "    trajectory_to_video(my_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with two timesteps\n",
    "\n",
    "\n",
    "dat_tuple = (dat,dat0)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for my_loss in ['sinkhorn_large_reg','sinkhorn_small_reg','energy_dist']:\n",
    "    model = learn_trajectory(z_target, my_loss=my_loss,n_batch=500)\n",
    "    save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "    trajectory_to_video(my_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_to_video(my_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
