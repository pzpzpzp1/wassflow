{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn  import functional as F \n",
    "from torch.autograd import Variable\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from torch.distributions import MultivariateNormal\n",
    "use_cuda = torch.cuda.is_available()\n",
    "from geomloss import SamplesLoss\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import gc\n",
    "import importlib\n",
    "import Utils\n",
    "importlib.reload(Utils)\n",
    "from Utils import InputMapping, BoundingBox, ImageDataset, SaveTrajectory\n",
    "from Utils import SaveTrajectory as st\n",
    "import ODEModel\n",
    "importlib.reload(ODEModel)\n",
    "from ODEModel import ODEfunc\n",
    "from ODEModel import FfjordModel\n",
    "import LearnTraj\n",
    "importlib.reload(LearnTraj);\n",
    "from LearnTraj import learn_trajectory\n",
    "\n",
    "##\n",
    "# import math\n",
    "# import numpy as np\n",
    "# from IPython.display import clear_output\n",
    "# import pdb\n",
    "# import time\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import torch\n",
    "# from torch import Tensor\n",
    "# from torch import nn\n",
    "# from torch.nn  import functional as F \n",
    "# from torch.autograd import Variable\n",
    "# from torchdiffeq import odeint_adjoint as odeint\n",
    "# from torch.distributions import MultivariateNormal\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# from geomloss import SamplesLoss\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# import gc\n",
    "# import importlib\n",
    "# import Utils\n",
    "# from Utils import InputMapping, BoundingBox, ImageDataset, SaveTrajectory\n",
    "# from Utils import SaveTrajectory as st\n",
    "# import ODEModel\n",
    "# from ODEModel import ODEfunc\n",
    "# from ODEModel import FfjordModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "caterpillar = 1-ImageDataset.import_img('caterpillar.png'); caterpillar/=caterpillar.max();\n",
    "butterfly = 255-ImageDataset.import_img('butterfly.jpg'); butterfly/=butterfly.max();\n",
    "circle = 255-ImageDataset.import_img('circle.jpeg'); circle/=circle.max();\n",
    "square = 1-ImageDataset.import_img('square.png'); square/=square.max();\n",
    "dset1 = ImageDataset(img=caterpillar*1,thresh=.8); \n",
    "dset2 = ImageDataset(img=butterfly*1,thresh=.8)\n",
    "dset3 = ImageDataset(img=circle*1,thresh=.8)\n",
    "dset4 = ImageDataset(img=square*1,thresh=.8)\n",
    "\n",
    "n = 10000; \n",
    "dat1 = dset1.sample(n); \n",
    "dat2 = dset2.sample(n); \n",
    "dat3 = dset3.sample(n)*.7;\n",
    "dat4 = dset4.sample(n);\n",
    "dat1*=-1; dat1[:,1]-=.1;\n",
    "dat2*=-1; dat2[:,1]+=.5; \n",
    "dat3[:,1]+=.1;\n",
    "\n",
    "plt.scatter(dat1.detach().numpy()[:,0],dat1.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='green')\n",
    "plt.scatter(dat2.detach().numpy()[:,0],dat2.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='red')\n",
    "# plt.scatter(dat3.detach().numpy()[:,0],dat3.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='magenta')\n",
    "# plt.scatter(dat4.detach().numpy()[:,0],dat4.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='orange')\n",
    "plt.axis('equal')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_target = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "model = FfjordModel(); \n",
    "# model.load_state('models/seq_state420_time_31.615391731262207.tar');\n",
    "# model.load_state('models/state310_time_22.49951934814453.tar');\n",
    "# model.load_state('models/state_start11.tar');\n",
    "# for my_loss in ['sinkhorn_small_reg']:\n",
    "# my_loss = 'sinkhorn_small_reg';\n",
    "my_loss = 'sinkhorn_large_reg';\n",
    "# %prun \n",
    "model1, losses1, separate_losses1 = learn_trajectory(z_target, my_loss=my_loss,n_iters=300,n_subsample=1000, model=model, save=True)\n",
    "model, losses2, separate_losses2 = learn_trajectory(z_target, my_loss=my_loss,n_iters=300,n_subsample=3000, model=model1, save=True)\n",
    "st.save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=500)\n",
    "st.save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=500,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "st.save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=500)\n",
    "st.save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=500,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test what weights are given to what frequencies in the first layer\n",
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "    pdat = param.data;\n",
    "    break;    \n",
    "pmags = torch.norm(param.data,p=2,dim=0);\n",
    "freqs = model.time_deriv_func.imap.B;\n",
    "nf = freqs.shape[0];\n",
    "nd = (pmags.shape[0]-2*nf)\n",
    "\n",
    "fmags = torch.norm(freqs,p=2,dim=1);\n",
    "xyfreqs = torch.cat([fmags, fmags],dim=0);\n",
    "print(xyfreqs.size())\n",
    "\n",
    "plt.plot(xyfreqs.cpu().numpy(), pmags[0:(nf*2)].cpu().numpy(),'.')\n",
    "plt.plot(np.zeros(nd), pmags[(nf*2):].cpu().numpy(),'.')\n",
    "\n",
    "# # freqs\n",
    "# # fmags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[1:]); \n",
    "plt.plot(separate_losses[0,50:]); \n",
    "plt.plot(separate_losses[1,50:]); \n",
    "# plt.plot(separate_losses[2,50:]); \n",
    "# plt.plot(separate_losses[3,50:]); \n",
    "# plt.plot(separate_losses[4,50:]); \n",
    "# plt.plot(separate_losses[5,50:]); \n",
    "# plt.plot(separate_losses[6,0:]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize ending sinkhorn costs as gradient on point clouds\n",
    "z_target = ImageDataset.normalize_samples(torch.stack((dat1,dat2)).to(device));\n",
    "T = z_target.shape[0];\n",
    "\n",
    "z_t = model(z_target[0,:,:], integration_times = torch.linspace(0,1,2).to(device),reverse=False);\n",
    "z_t_b = model(z_target[T-1,:,:], integration_times = torch.linspace(0,1,2).to(device),reverse=True);\n",
    "forward = z_t[T-1,:,:].cpu().detach().numpy();\n",
    "backward = z_t_b[T-1,:,:].cpu().detach().numpy();\n",
    "\n",
    "my_loss_f = SamplesLoss(\"sinkhorn\", p=2, blur=0.01);\n",
    "loss_f = my_loss_f(z_target[T-1,:,:], z_t[T-1,:,:])\n",
    "loss_b = my_loss_f(z_target[0,:,:], z_t_b[T-1,:,:])\n",
    "\n",
    "graddirs_f = torch.autograd.grad(loss_f, z_t)[0][T-1,:,:]\n",
    "graddirs_b = torch.autograd.grad(loss_b, z_t_b)[0][T-1,:,:]\n",
    "\n",
    "pos_f = z_t.cpu().detach().numpy()\n",
    "pos_b = z_t_b.cpu().detach().numpy()\n",
    "dirs_f = graddirs_f.cpu().detach().numpy()\n",
    "dirs_b = graddirs_b.cpu().detach().numpy()\n",
    "\n",
    "import os\n",
    "plt.axis('equal')\n",
    "plt.scatter(pos_b[0,:,0], pos_b[0,:,1], s=10, alpha=.5, linewidths=0, c='green', edgecolors='black')\n",
    "plt.scatter(forward[:,0], forward[:,1], s=10, alpha=.5, linewidths=0, c='red', edgecolors='black')\n",
    "plt.quiver(pos_f[T-1,:,0], pos_f[T-1,:,1], dirs_f[:,0], dirs_f[:,1],scale=.0001)\n",
    "plt.savefig(os.path.join('./', f\"viz_backward.jpg\"),dpi=400); plt.clf()\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.scatter(pos_f[0,:,0], pos_f[0,:,1], s=10, alpha=.5, linewidths=0, c='green', edgecolors='black')\n",
    "plt.scatter(backward[:,0], backward[:,1], s=10, alpha=.5, linewidths=0, c='red', edgecolors='black')\n",
    "plt.quiver(pos_b[T-1,:,0], pos_b[T-1,:,1], dirs_b[:,0], dirs_b[:,1],scale=.0001)\n",
    "plt.savefig(os.path.join('./', f\"viz_forward.jpg\"),dpi=400); plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trying other shapes\n",
    "\n",
    "square = np.zeros([20,20])\n",
    "square[6:14,:8] = 1\n",
    "\n",
    "two_square = np.zeros([20,20])\n",
    "two_square[:5,14:] = 1\n",
    "two_square[15:,14:] = 1\n",
    "\n",
    "\n",
    "annulus = import_img('annulus.png')\n",
    "circle = 255-import_img('circle.jpeg')\n",
    "\n",
    "dset = ImageDataset(img=square)\n",
    "dset1 = ImageDataset(img=two_square)\n",
    "\n",
    "n = 500\n",
    "dat = dset.sample(n)\n",
    "dat1 = dset1.sample(n)\n",
    "plt.scatter(dat.detach().numpy()[:,0],dat.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='green')\n",
    "plt.scatter(dat1.detach().numpy()[:,0],dat1.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='red')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make half moon dataset\n",
    "import sklearn.datasets\n",
    "\n",
    "moons, labels = sklearn.datasets.make_moons(n,noise=.1) #generates two half moons\n",
    "mask = (labels == 0)\n",
    "one_moon = moons[mask,:] # only keep one moon\n",
    "\n",
    "def rot_mat(theta0):\n",
    "    #computes rotation matrix of angle theta\n",
    "    return np.array([[np.cos(theta0),-np.sin(theta0)],[np.sin(theta0),np.cos(theta0)]])\n",
    "\n",
    "theta0 = np.pi/2\n",
    "theta1 = np.pi\n",
    "\n",
    "rot0 = rot_mat(theta0)\n",
    "rot1 = rot_mat(theta1)\n",
    "\n",
    "# apply rotation to the moon\n",
    "one_moon_rot0 = np.dot(one_moon,rot0)\n",
    "one_moon_rot1 = np.dot(one_moon,rot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize rotated moons\n",
    "\n",
    "plt.scatter(one_moon[:,0],one_moon[:,1], color='blue')\n",
    "plt.scatter(one_moon_rot0[:,0],one_moon_rot0[:,1], color='orange')\n",
    "plt.scatter(one_moon_rot1[:,0],one_moon_rot1[:,1], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with three timesteps\n",
    "\n",
    "dat = torch.tensor(one_moon,dtype=torch.float)\n",
    "dat0 = torch.tensor(one_moon_rot0,dtype=torch.float)\n",
    "dat1 = torch.tensor(one_moon_rot1,dtype=torch.float)\n",
    "\n",
    "dat_tuple = (dat,dat0,dat1)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for my_loss in ['sinkhorn_large_reg','sinkhorn_small_reg','energy_dist']:\n",
    "    model = learn_trajectory(z_target, my_loss=my_loss,n_batch=500)\n",
    "    save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "    trajectory_to_video(my_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with two timesteps\n",
    "\n",
    "\n",
    "dat_tuple = (dat,dat0)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for my_loss in ['sinkhorn_large_reg','sinkhorn_small_reg','energy_dist']:\n",
    "    model = learn_trajectory(z_target, my_loss=my_loss,n_batch=500)\n",
    "    save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "    trajectory_to_video(my_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
