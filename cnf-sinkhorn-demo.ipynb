{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import pdb, time, math, numpy as np, gc, importlib, torch, os, cv2 as cv, ODEModel, matplotlib\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F \n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torchdiffeq import odeint_adjoint as odeint \n",
    "from geomloss import SamplesLoss\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import Utils, LearnVelTraj\n",
    "importlib.reload(Utils)\n",
    "from Utils import InputMapping, BoundingBox, ImageDataset, SaveTrajectory, ezshow, SaveTrajectory as st, MiscTransforms\n",
    "importlib.reload(ODEModel)\n",
    "from ODEModel import velocMLP, FfjordModel\n",
    "importlib.reload(LearnVelTraj);\n",
    "from LearnVelTraj import learn_vel_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-40167b0cd115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mxt_trajs_OT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cubic_OT_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n\u001b[0m\u001b[1;32m     25\u001b[0m                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n\u001b[1;32m     26\u001b[0m st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render_tight',\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ## TRAIN halloween ish. Concatenated OT maps only.\n",
    "f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 10000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='red')\n",
    "ezshow(dat2, col='yellow')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='black')\n",
    "\n",
    "outfolder = \"results/experiment_spook_cubic_OT/\"\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "\n",
    "xt_trajs_OT = st.get_cubic_OT_trajectory(keyframes, nsteps=20, n=2000)\n",
    "\n",
    "st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "                       dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n",
    "st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render_tight',\n",
    "                       dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False,tightBB=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN FISH234: Use OT cubic splines\n",
    "# f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "# f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_fish234_OT_cubic/\"\n",
    "\n",
    "# xt_trajs_OT = st.get_cubic_OT_trajectory(keyframes, nsteps=20, n=2000)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='cubic_OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='cubic_OT_render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False,tightBB=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. Concatenated OT maps only.\n",
    "# # f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# # f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# # f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# # f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# # n_inner = 10000;\n",
    "# # n_sil = 10000 - n_inner;\n",
    "# # dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# # dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# # dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# # dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# # ezshow(dat1, col='red')\n",
    "# # ezshow(dat2, col='yellow')\n",
    "# # ezshow(dat3, col='orange')\n",
    "# # ezshow(dat4, col='black')\n",
    "\n",
    "# # outfolder = \"results/experiment_spook_OT/\"\n",
    "\n",
    "# # keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# # xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=2000, ot_type=2)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False,tightBB=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN halloween ish. jerk .01, polar .1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_polar/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. jerk .01, radial .1\n",
    "# # f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# # f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# # f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# # f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# # n_inner = 10000;\n",
    "# # n_sil = 10000 - n_inner;\n",
    "# # dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# # dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# # dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# # dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# # ezshow(dat1, col='red')\n",
    "# # ezshow(dat2, col='yellow')\n",
    "# # ezshow(dat3, col='orange')\n",
    "# # ezshow(dat4, col='black')\n",
    "\n",
    "# # keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# # model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# # outfolder = \"results/experiment_spook_radial/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# # xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "# #                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "# #                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: noreg. sigma=7\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 7, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_noreg_sigma7/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: noreg. sigma=5\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 5, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_noreg_sigma5/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. div 1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_div1/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. rigid 2\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_rigid/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. curl on trajectory .1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_curlmean_p1/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. accel = 1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_accel_1/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. accel = 5\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_accel_5/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # # ## TRAIN carcination. jerk=.01. seems to look fine. not really going for a point here. but it looks cool enough i guess.\n",
    "# # f1 = ImageDataset('frames/lobster.jpg',noise_std=0,thresh=.50,binary=False); \n",
    "# # f2 = ImageDataset('frames/crab.jpg',noise_std=0); \n",
    "\n",
    "# # n_inner = 10000;\n",
    "# # n_sil = 10000 - n_inner;\n",
    "# # dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1.7, -1], center = [0,0], rotate = 0),0); \n",
    "# # dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1], center = [.9,0], rotate = -np.pi/2),0); \n",
    "\n",
    "# # ezshow(dat1, col='red')\n",
    "# # ezshow(dat2, col='blue')\n",
    "# # plt.axis('equal')\n",
    "\n",
    "# # keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# # model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# # outfolder = \"results/experiment_carcinization_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "# # xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "# #                        nsteps=40, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=10, cycle=False, lw=0, contrast=2, Nrbf = 100000, keyframes=False, tightBB=True)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "# #                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # after running rect_base and rect_slight_div, run this to get areas.\n",
    "# points = xt_trajs_1[0];\n",
    "# areas = np.zeros(points.shape[2])\n",
    "# for i in range(points.shape[2]):\n",
    "#     chull = scipy.spatial.ConvexHull(points[:,:,i])\n",
    "#     areas[i] = chull.volume\n",
    "# areas1=areas\n",
    "\n",
    "# points = xt_trajs_2[0];\n",
    "# areas = np.zeros(points.shape[2])\n",
    "# for i in range(points.shape[2]):\n",
    "#     chull = scipy.spatial.ConvexHull(points[:,:,i])\n",
    "#     areas[i] = chull.volume\n",
    "# areas2=areas\n",
    "\n",
    "# print(areas1[-1]-areas1[0]) \n",
    "# print(areas1.max()/areas1[0]) \n",
    "\n",
    "# print(areas2[-1]-areas2[0]) \n",
    "# print(areas2.max()/areas2[0]) \n",
    "\n",
    "# plt.plot(areas1/areas3[0],'r')\n",
    "# plt.plot(areas2/areas3[0],'g')\n",
    "\n",
    "# np.savetxt('results/outcache/areas1.txt', areas1)\n",
    "# np.savetxt('results/outcache/areas2.txt', areas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # ## TRAIN rectangles. KE=.1, div=1\n",
    "# n_inner = 10000;\n",
    "# dat1 = torch.rand(n_inner,2)-.5\n",
    "# dat2 = torch.rand(n_inner,2)-.5\n",
    "# dat2[:,0]*=3;dat2[:,1]/=3;\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_rects_slight_div/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=40, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)\n",
    "# xt_trajs_2 = xt_trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # ## TRAIN rectangles. KE=.1, div=0\n",
    "# # optimal transport from (1,1) square to (.33,3) rectangle should result in an area increase of 33.3% at the middle of the trajectory.\n",
    "# n_inner = 10000;\n",
    "# dat1 = torch.rand(n_inner,2)-.5\n",
    "# dat2 = torch.rand(n_inner,2)-.5\n",
    "# dat2[:,0]*=3;dat2[:,1]/=3;\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_rects_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=40, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)\n",
    "# xt_trajs_1 = xt_trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # ## TRAIN bars. KE=.01, rigid=10\n",
    "# f1 = ImageDataset('frames/square.png',noise_std=0); \n",
    "# rotate = torch.tensor(.3)\n",
    "# s, c = (torch.sin(rotate), torch.cos(rotate))\n",
    "# rot = torch.stack([torch.stack([c, -s]), torch.stack([s, c])])\n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, .1]),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, -.1]),0); \n",
    "# dat1 = dat1 @ rot\n",
    "# dat2 = dat2 @ rot.t()\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_bars_more_rigid/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "# #                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN bars. KE=.01, rigid=1\n",
    "# f1 = ImageDataset('frames/square.png',noise_std=0); \n",
    "# rotate = torch.tensor(.3)\n",
    "# s, c = (torch.sin(rotate), torch.cos(rotate))\n",
    "# rot = torch.stack([torch.stack([c, -s]), torch.stack([s, c])])\n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, .1]),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, -.1]),0); \n",
    "# dat1 = dat1 @ rot\n",
    "# dat2 = dat2 @ rot.t()\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_bars_rigid/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN bars. KE=.01\n",
    "# f1 = ImageDataset('frames/square.png',noise_std=0); \n",
    "# rotate = torch.tensor(.3)\n",
    "# s, c = (torch.sin(rotate), torch.cos(rotate))\n",
    "# rot = torch.stack([torch.stack([c, -s]), torch.stack([s, c])])\n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, .1]),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, -.1]),0); \n",
    "# dat1 = dat1 @ rot\n",
    "# dat2 = dat2 @ rot.t()\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_bars_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "# #                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000,keyframes=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # horse down to horse up - jerk = .01\n",
    "# im1 = ImageDataset('frames/horse1.jpg'); \n",
    "# im2 = ImageDataset('frames/horse2.jpg'); \n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d1 = im1.sample(n_inner, n_sil, center = [1, .5]); \n",
    "# d2 = im2.sample(n_inner, n_sil, center = [1, .5], scale=[-1, -1]); \n",
    "# dat1 = torch.cat(d1,0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_horseup_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=2000, ot_type=2)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=2, keyframes=False, Nrbf = 100000)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=2, keyframes=False, Nrbf = 100000, Nqvr=1, showVelocity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # horse character to horse - jerk = .01\n",
    "im1 = ImageDataset('frames/horse_charac.jpg'); \n",
    "im2 = ImageDataset('frames/horse.jpg'); \n",
    "\n",
    "n_inner = 7000;\n",
    "n_sil = 10000 - n_inner;\n",
    "d1 = im1.sample(n_inner, n_sil, center = [1, .5]); \n",
    "d2 = im2.sample(n_inner, n_sil, center = [1, .5], scale=[-1, -1]); \n",
    "\n",
    "dat1 = torch.cat(d1,0)\n",
    "dat2 = torch.cat(d2,0)\n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_horse_base/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000)\n",
    "\n",
    "xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=2000, ot_type=2)\n",
    "st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "                       dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000, Nqvr=1, showVelocity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # horse character to horse - jerk = .01\n",
    "# generate points\n",
    "im1 = ImageDataset('frames/horse_charac.jpg'); \n",
    "im2 = ImageDataset('frames/horse.jpg'); \n",
    "\n",
    "n_inner = 7000;\n",
    "n_sil = 10000 - n_inner;\n",
    "d1 = im1.sample(n_inner, n_sil, center = [1, .5]); \n",
    "d2 = im2.sample(n_inner, n_sil, center = [1, .5], scale=[-1, -1]); \n",
    "\n",
    "dat1 = torch.cat(d1,0)\n",
    "dat2 = torch.cat(d2,0)\n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_horse_base/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=10000)\n",
    "np.savetxt(outfolder+'xt_trajs.txt', torch.cat((torch.tensor(xt_trajs[0].shape), xt_trajs[0].reshape(-1)),0))\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000)\n",
    "\n",
    "xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=10000, ot_type=2)\n",
    "np.savetxt(outfolder+'xt_trajs_OT.txt', torch.cat((torch.tensor(xt_trajs_OT[0].shape), xt_trajs_OT[0].reshape(-1)),0))\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000, Nqvr=1, showVelocity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BUTTERFLY->CAT->CATERPILLAR - KE = .01, radialke = .1\n",
    "# im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "# im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "# im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "# im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [0.05, -.5]); \n",
    "# d1a = im1.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d1b = im1b.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d6 = im6.sample(n_inner, n_sil, center = [2, -.3]); \n",
    "\n",
    "# dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# dat6 = torch.cat(d6,0)\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat6, col='magenta')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat6, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_BCC_radial/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=4000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=1, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BUTTERFLY->CAT->CATERPILLAR - base. KE = .01\n",
    "# im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "# im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "# im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "# im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [0.05, -.5]); \n",
    "# d1a = im1.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d1b = im1b.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d6 = im6.sample(n_inner, n_sil, center = [2, -.3]); \n",
    "\n",
    "# dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# dat6 = torch.cat(d6,0)\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat6, col='magenta')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat6, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_BCC_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=4000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=1, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN FISH234 cycle. Jerk=.01. signedcurl=.1 curl everywhere\n",
    "# f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "# f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_fish234_signedcurl_even/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=30, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN FISH234 cycle. Jerk=.01. signedcurl=.1 average curl\n",
    "# f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "# f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_fish234_signedcurl/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN FISH234 cycle. Jerk=.01.\n",
    "# f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "# f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_fish234/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## GENERATE CYCLIC BUTTERFLY->CAT->CATERPILLAR. enforce completely cyclic.\n",
    "# im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "# im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "# im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "# im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [1, -1.2]); \n",
    "# d1a = im1.sample(n_inner, n_sil, center = [0, .13]); \n",
    "# d1b = im1b.sample(n_inner, n_sil, center = [0, .13]); \n",
    "# d6 = im6.sample(n_inner, n_sil, center = [2, .15]); \n",
    "\n",
    "# dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# dat6 = torch.cat(d6,0)\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat6, col='magenta')\n",
    "\n",
    "# ## TRAIN CYCLIC BUTTERFLY->CAT->CATERPILLAR. .1 radial, .01 jerk\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat6, dat2, dat1)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 4, in_features=3, out_features=2, incrementalMask = True,  Tperiod = len(keyframes)-1).to(device)\n",
    "# outfolder = \"results/experiment_BCC_cyclic/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=True, lw=.5, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN umbrella. Jerk=.01. poor temporal consistency because of discretized ot registration.\n",
    "# f1 = ImageDataset('frames/birdflock_start.jpg',noise_std=0,thresh=.9,binary=False); \n",
    "# f2 = ImageDataset('frames/umbrella.jpg',noise_std=0,thresh=.9); \n",
    "# f3 = ImageDataset('frames/birdflock_end.jpg',noise_std=.1,thresh=1,binary=False); \n",
    "\n",
    "# # dat1 = torch.cat(f1.sample(1000, 0, scale = [1.5, -1.2], center = [-1.5, .125], rotate = 0),0); \n",
    "# # dat1 = torch.randn(1000,2); dat1[:,0]*=.5; dat1[:,1]*=.2; dat1[:,0]-=.6\n",
    "# dat2 = torch.randn(1000,2); dat2[:,0]*=.2; dat2[:,1]*=.1; dat2[:,0]-=.2; dat2[:,1]+=.1\n",
    "# dat1 = dat2.clone(); dat1[:,0]-=.5\n",
    "# dat3 = torch.cat(f2.sample(900, 100, scale = [1, -1.1], center = [.13, -.05], rotate = 0),0); \n",
    "# dat4 = torch.cat(f3.sample(1000, 0, scale = [2, -2], center = [.2, .2], rotate = 0),0); \n",
    "# dat5 = torch.randn(1000,2); dat5[:,0]*=.8; dat5[:,1]*=.8; dat5[:,1]+=.5\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='orange')\n",
    "# ezshow(dat3, col='red')\n",
    "# ezshow(dat4, col='blue')\n",
    "# # ezshow(dat5, col='green')\n",
    "\n",
    "# # keyframes = torch.stack((dat1, dat2, dat3, dat4, dat5)).to(device);\n",
    "# keyframes = torch.stack((dat1, dat2, dat3, dat4)).to(device);\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_umbrella_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = True, lr = 1e-4, scaling = .4, normalize=False)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=100)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_points',\n",
    "#                        dpiv=600, sigma=.01, knn=1, cycle=False, lw=.01, contrast=1, Nrbf = 0, keyframes=False, showVelocity=False, plotKeypoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, div=1, rig.1\n",
    "f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.11, .125], rotate = 0),0); \n",
    "dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.13, -.05], rotate = -np.pi*.375),0); \n",
    "dat3 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, -.2], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='blue')\n",
    "\n",
    "keyframes = torch.stack((dat1, dat2, dat3)).to(device);\n",
    "\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MMF_rigdiv/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=False)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=10, cycle=True, lw=0, contrast=3, Nrbf = 100000,keyframes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, \n",
    "# f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.2, .5], rotate = -np.pi/7),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 4, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_MF2_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=10, cycle=True, lw=0, contrast=3, Nrbf = 100000,keyframes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TRAIN MF. Jerk=.01\n",
    "# f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.11, .325], rotate = 0),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.13, .15], rotate = -np.pi*.375),0); \n",
    "# dat3 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='blue')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_MMF_base/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=10, cycle=True, lw=0, contrast=3, Nrbf = 100000,keyframes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## GENERATE FISH IMAGES\n",
    "f1 = ImageDataset('frames/fish1.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1.2, -1], center = [-.07, .9], rotate = -np.pi/2),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.9, 0], rotate = -np.pi),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.9], rotate = np.pi/2),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.9, 0], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN FISH1234 circle. Jerk=.01\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RENDER ABOVE\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 2, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle/\"\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN FISH1234 circle. Jerk=.01. rigid=.1, curl-pi=.1\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle_morecurl_andrigid/\"\n",
    "model.load_state(outfolder + 'models/state_0050.tar')\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=953, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 5e-5, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RENDER ABOVE\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 2, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle_morecurl_andrigid/\"\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "model.load_state(outfolder + 'models/state_0050.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True, lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, rigid=2\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MF2_rigid/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE MF IMAGES\n",
    "f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, rigid=2\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MF_rigid/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MF_base/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE FISH IMAGES\n",
    "f1 = ImageDataset('frames/fish1.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [-.7, .6], rotate = 0),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [.7, -.6], rotate = 0),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [1, -1.1], center = [.7, .6], rotate = 0),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [1, -1.1], center = [-.7, -.6], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN FISH1234. Jerk=.01, curl=3\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_min3curl/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENDER FISH1234. Jerk=.01, curl=3\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234_min3curl/\"\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN FISH1234. Jerk=.01, curl=1\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_mincurl/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN FISH1234. Jerk=.01\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENDER FISH1234\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 2, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234/\"\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE BUNCH OF IMAGES\n",
    "im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "im3 = ImageDataset('frames/circle.jpeg'); \n",
    "im4 = ImageDataset('frames/baldhead.jpeg'); \n",
    "im5 = ImageDataset('frames/square.png'); \n",
    "im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "n_inner = 7000;\n",
    "n_sil = 10000 - n_inner;\n",
    "d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [0.05, -.5]); \n",
    "d1a = im1.sample(n_inner, n_sil, center = [0, 0]); \n",
    "d1b = im1b.sample(n_inner, n_sil, center = [0, 0]); \n",
    "d3 = im3.sample(n_inner, n_sil, center = [1, .5]); \n",
    "d4 = im4.sample(n_inner, n_sil, center = [1, -.5]); \n",
    "d5 = im5.sample(n_inner, n_sil, center = [1.9, .3]); \n",
    "d6 = im6.sample(n_inner, n_sil, center = [2, -.3]); \n",
    "\n",
    "dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "dat2 = torch.cat(d2,0)\n",
    "dat3 = torch.cat(d3,0)\n",
    "dat4 = torch.cat(d4,0)\n",
    "dat5 = torch.cat(d5,0)\n",
    "dat6 = torch.cat(d6,0)\n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')\n",
    "ezshow(dat5, col='blue')\n",
    "ezshow(dat6, col='magenta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
