{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import pdb\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn  import functional as F \n",
    "from torch.autograd import Variable\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from torch.distributions import MultivariateNormal\n",
    "use_cuda = torch.cuda.is_available()\n",
    "from geomloss import SamplesLoss\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import gc\n",
    "import importlib\n",
    "import Utils\n",
    "importlib.reload(Utils)\n",
    "from Utils import InputMapping, BoundingBox, ImageDataset, SaveTrajectory\n",
    "from Utils import SaveTrajectory as st\n",
    "import ODEModel\n",
    "importlib.reload(ODEModel)\n",
    "from ODEModel import ODEfunc\n",
    "from ODEModel import FfjordModel\n",
    "import LearnTraj\n",
    "importlib.reload(LearnTraj);\n",
    "from LearnTraj import learn_trajectory\n",
    "import os;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "caterpillar,im = ImageDataset.import_img('caterpillar.png'); caterpillar=1-caterpillar; caterpillar/=caterpillar.max();\n",
    "butterfly,im = ImageDataset.import_img('butterfly.jpg'); butterfly=255-butterfly; butterfly/=butterfly.max();\n",
    "circle,im = ImageDataset.import_img('circle.jpeg'); circle=255-circle; circle/=circle.max();\n",
    "square,im = ImageDataset.import_img('square.png', rgb_weights=[0.2989, 0.5870, 0.1140,0]); square=1-square; square/=square.max();\n",
    "cat1,im = ImageDataset.import_img('cat1.png', rgb_weights = [0.2989, 0.5870, 0.1140, 1]); cat1/=cat1.max();\n",
    "dset1 = ImageDataset(img=caterpillar*1,thresh=.8); \n",
    "dset2 = ImageDataset(img=butterfly*1,thresh=.8)\n",
    "dset3 = ImageDataset(img=circle*1,thresh=.8)\n",
    "dset4 = ImageDataset(img=square*1,thresh=.8)\n",
    "dset5 = ImageDataset(img=cat1*1,thresh=.8)\n",
    "\n",
    "n = 10000; \n",
    "dat1 = dset1.sample(n); \n",
    "dat2 = dset2.sample(n); \n",
    "dat3 = dset3.sample(n)*.7;\n",
    "dat4 = dset4.sample(n);\n",
    "dat5 = dset5.sample(n);\n",
    "dat1*=-1; dat1[:,1]-=.1;\n",
    "dat2*=-1; dat2[:,1]+=.5; \n",
    "dat3[:,1]+=1.5;\n",
    "dat5[:,1]*=-1;\n",
    "\n",
    "plt.scatter(dat1.detach().numpy()[:,0],dat1.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='green')\n",
    "plt.scatter(dat2.detach().numpy()[:,0],dat2.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='red')\n",
    "# plt.scatter(dat3.detach().numpy()[:,0],dat3.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='magenta')\n",
    "# plt.scatter(dat4.detach().numpy()[:,0],dat4.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='orange')\n",
    "# plt.scatter(dat5.detach().numpy()[:,0],dat5.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c='yellow')\n",
    "plt.axis('equal')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_target = ImageDataset.normalize_samples(torch.stack((dat2, dat1)).to(device));\n",
    "model = FfjordModel().to(device); \n",
    "# model.load_state('models/seq_state420_time_31.615391731262207.tar');\n",
    "# model.load_state('models/state310_time_22.49951934814453.tar');\n",
    "# model.load_state('models/state_start.tar');\n",
    "# for my_loss in ['sinkhorn_small_reg']:\n",
    "# my_loss = 'sinkhorn_small_reg';\n",
    "my_loss = 'sinkhorn_large_reg';\n",
    "# %prun \n",
    "model, losses, separate_losses, lrs, n_subs = learn_trajectory(z_target, my_loss=my_loss,n_iters = 4000,n_subsample=200, model=model, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st.gpu_usage()\n",
    "# z_target.shape\n",
    "# z_target = ImageDataset.normalize_samples(torch.stack((dat2, dat1)).to(device));\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# z_target = ImageDataset.normalize_samples(torch.stack((dat2, dat1)).to(device));\n",
    "# model = FfjordModel().to(device); model.load_state('models/state_start.tar'); # print(next(model.parameters()).is_cuda)\n",
    "# my_loss = 'sinkhorn_large_reg';\n",
    "myln = my_loss+'_0';\n",
    "st.save_trajectory(model,z_target[:,1:4000,:],myln, savedir='imgs', nsteps=100, memory=0.01, n=500,dpiv=400)\n",
    "st.gpu_usage()\n",
    "st.trajectory_to_video(myln, savedir='imgs', mp4_fn='transform.mp4')\n",
    "\n",
    "# integration_times = torch.linspace(0,z_target.shape[0]-1,2).to(device);\n",
    "# model(z_target[1,:,:], integration_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "st.gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test what weights are given to what frequencies in the first layer\n",
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "    pdat = param.data;\n",
    "    break;    \n",
    "pmags = torch.norm(param.data,p=2,dim=0);\n",
    "freqs = model.time_deriv_func.imap.B;\n",
    "nf = freqs.shape[0];\n",
    "nd = (pmags.shape[0]-2*nf)\n",
    "\n",
    "fmags = torch.norm(freqs,p=2,dim=1);\n",
    "xyfreqs = torch.cat([fmags, fmags],dim=0);\n",
    "print(xyfreqs.size())\n",
    "\n",
    "plt.plot(xyfreqs.cpu().numpy(), pmags[0:(nf*2)].cpu().numpy(),'.')\n",
    "plt.plot(np.zeros(nd), pmags[(nf*2):].cpu().numpy(),'.')\n",
    "plt.savefig(os.path.join('./', f\"viz_freqs.jpg\"),dpi=400); \n",
    "# # freqs\n",
    "# # fmags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=50;end=30000;\n",
    "plt.plot(losses[start:end]); \n",
    "plt.plot(separate_losses[0,start:end],'g'); \n",
    "plt.plot(separate_losses[1,start:end],'r'); \n",
    "# plt.plot(separate_losses[2,50:]); \n",
    "# plt.plot(separate_losses[3,50:]); \n",
    "# plt.plot(separate_losses[4,50:]); \n",
    "# plt.plot(separate_losses[5,50:]); \n",
    "# plt.plot(separate_losses[6,0:]);\n",
    "plt.savefig(os.path.join('./', f\"viz_loss.jpg\"),dpi=400); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig,(ax1,ax2))=plt.subplots(2,1)\n",
    "ax1.plot(n_subs[start:end],'r'); ax1.set_ylabel('n_sub')\n",
    "ax2.plot(lrs[start:end],'g'); ax2.set_ylabel('lr') \n",
    "plt.savefig(os.path.join('./', f\"viz_stat.jpg\"),dpi=400); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize ending sinkhorn costs as gradient on point clouds\n",
    "# z_target = ImageDataset.normalize_samples(torch.stack((dat1,dat4)).to(device));\n",
    "T = z_target.shape[0];\n",
    "\n",
    "z_t = model(z_target[0,:,:], integration_times = torch.linspace(0,T-1,T).to(device),reverse=False);\n",
    "z_t_b = model(z_target[T-1,:,:], integration_times = torch.linspace(0,T-1,T).to(device),reverse=True);\n",
    "forward = z_t[T-1,:,:].cpu().detach().numpy();\n",
    "backward = z_t_b[T-1,:,:].cpu().detach().numpy();\n",
    "\n",
    "my_loss_f = SamplesLoss(\"sinkhorn\", p=2, blur=0.01);\n",
    "loss_f = my_loss_f(z_target[T-1,:,:], z_t[T-1,:,:])\n",
    "loss_b = my_loss_f(z_target[0,:,:], z_t_b[T-1,:,:])\n",
    "\n",
    "graddirs_f = torch.autograd.grad(loss_f, z_t)[0][T-1,:,:]\n",
    "graddirs_b = torch.autograd.grad(loss_b, z_t_b)[0][T-1,:,:]\n",
    "\n",
    "pos_f = z_t.cpu().detach().numpy()\n",
    "pos_b = z_t_b.cpu().detach().numpy()\n",
    "dirs_f = graddirs_f.cpu().detach().numpy()\n",
    "dirs_b = graddirs_b.cpu().detach().numpy()\n",
    "\n",
    "import os\n",
    "plt.axis('equal')\n",
    "plt.scatter(pos_b[0,:,0], pos_b[0,:,1], s=10, alpha=.5, linewidths=0, c='green', edgecolors='black')\n",
    "plt.scatter(forward[:,0], forward[:,1], s=10, alpha=.5, linewidths=0, c='red', edgecolors='black')\n",
    "plt.quiver(pos_f[T-1,:,0], pos_f[T-1,:,1], dirs_f[:,0], dirs_f[:,1],scale=.0001)\n",
    "plt.savefig(os.path.join('./', f\"viz_backward.jpg\"),dpi=400); plt.clf()\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.scatter(pos_f[0,:,0], pos_f[0,:,1], s=10, alpha=.5, linewidths=0, c='green', edgecolors='black')\n",
    "plt.scatter(backward[:,0], backward[:,1], s=10, alpha=.5, linewidths=0, c='red', edgecolors='black')\n",
    "plt.quiver(pos_b[T-1,:,0], pos_b[T-1,:,1], dirs_b[:,0], dirs_b[:,1],scale=.0001)\n",
    "plt.savefig(os.path.join('./', f\"viz_forward.jpg\"),dpi=400); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trying other shapes\n",
    "\n",
    "square = np.zeros([20,20])\n",
    "square[6:14,:8] = 1\n",
    "\n",
    "two_square = np.zeros([20,20])\n",
    "two_square[:5,14:] = 1\n",
    "two_square[15:,14:] = 1\n",
    "\n",
    "\n",
    "annulus = import_img('annulus.png')\n",
    "circle = 255-import_img('circle.jpeg')\n",
    "\n",
    "dset = ImageDataset(img=square)\n",
    "dset1 = ImageDataset(img=two_square)\n",
    "\n",
    "n = 500\n",
    "dat = dset.sample(n)\n",
    "dat1 = dset1.sample(n)\n",
    "plt.scatter(dat.detach().numpy()[:,0],dat.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='green')\n",
    "plt.scatter(dat1.detach().numpy()[:,0],dat1.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='red')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make half moon dataset\n",
    "import sklearn.datasets\n",
    "\n",
    "moons, labels = sklearn.datasets.make_moons(n,noise=.1) #generates two half moons\n",
    "mask = (labels == 0)\n",
    "one_moon = moons[mask,:] # only keep one moon\n",
    "\n",
    "def rot_mat(theta0):\n",
    "    #computes rotation matrix of angle theta\n",
    "    return np.array([[np.cos(theta0),-np.sin(theta0)],[np.sin(theta0),np.cos(theta0)]])\n",
    "\n",
    "theta0 = np.pi/2\n",
    "theta1 = np.pi\n",
    "\n",
    "rot0 = rot_mat(theta0)\n",
    "rot1 = rot_mat(theta1)\n",
    "\n",
    "# apply rotation to the moon\n",
    "one_moon_rot0 = np.dot(one_moon,rot0)\n",
    "one_moon_rot1 = np.dot(one_moon,rot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize rotated moons\n",
    "\n",
    "plt.scatter(one_moon[:,0],one_moon[:,1], color='blue')\n",
    "plt.scatter(one_moon_rot0[:,0],one_moon_rot0[:,1], color='orange')\n",
    "plt.scatter(one_moon_rot1[:,0],one_moon_rot1[:,1], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with three timesteps\n",
    "\n",
    "dat = torch.tensor(one_moon,dtype=torch.float)\n",
    "dat0 = torch.tensor(one_moon_rot0,dtype=torch.float)\n",
    "dat1 = torch.tensor(one_moon_rot1,dtype=torch.float)\n",
    "\n",
    "dat_tuple = (dat,dat0,dat1)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for my_loss in ['sinkhorn_large_reg','sinkhorn_small_reg','energy_dist']:\n",
    "    model = learn_trajectory(z_target, my_loss=my_loss,n_batch=500)\n",
    "    save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "    trajectory_to_video(my_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with two timesteps\n",
    "\n",
    "\n",
    "dat_tuple = (dat,dat0)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for my_loss in ['sinkhorn_large_reg','sinkhorn_small_reg','energy_dist']:\n",
    "    model = learn_trajectory(z_target, my_loss=my_loss,n_batch=500)\n",
    "    save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "    trajectory_to_video(my_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
