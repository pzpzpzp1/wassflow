{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import pdb\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn  import functional as F \n",
    "from torch.autograd import Variable\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from torch.distributions import MultivariateNormal\n",
    "use_cuda = torch.cuda.is_available()\n",
    "from geomloss import SamplesLoss\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import gc\n",
    "import importlib\n",
    "import Utils\n",
    "importlib.reload(Utils)\n",
    "from Utils import InputMapping, BoundingBox, ImageDataset, SaveTrajectory\n",
    "from Utils import SaveTrajectory as st\n",
    "import ODEModel\n",
    "importlib.reload(ODEModel)\n",
    "from ODEModel import ODEfunc, Siren\n",
    "from ODEModel import FfjordModel\n",
    "import LearnTraj\n",
    "importlib.reload(LearnTraj);\n",
    "from LearnTraj import learn_trajectory\n",
    "import os;\n",
    "import cv2 as cv;\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = ImageDataset('butterfly.jpg'); \n",
    "im1b = ImageDataset('butterflyfilled.jpg'); \n",
    "im2 = ImageDataset('caterpillar.png', noise_std = .005); \n",
    "im3 = ImageDataset('circle.jpeg'); \n",
    "im4 = ImageDataset('baldhead.jpeg'); \n",
    "im5 = ImageDataset('square.png'); \n",
    "im6 = ImageDataset('cat1.png'); \n",
    "\n",
    "n = 10000;\n",
    "dat2, dat2sil = im2.sample(n, scale = [-1, -1], center = [0.05, -.5]); \n",
    "dat1, g = im1.sample(n, center = [0, 0]); \n",
    "g, dat1sil = im1b.sample(n, center = [0, 0]); \n",
    "dat3, dat3sil = im3.sample(n, center = [1, .5]); \n",
    "dat4, dat4sil = im4.sample(n, center = [1, -.5]); \n",
    "dat5, dat5sil = im5.sample(n, center = [1.9, .3]); \n",
    "dat6, dat6sil = im6.sample(n, center = [2, -.3]); \n",
    "\n",
    "def ezshow(dat, col='green'):\n",
    "    plt.scatter(dat.detach().numpy()[:,0],dat.detach().numpy()[:,1],s=10, alpha=0.5, linewidths=0,c=col); plt.axis('equal'); \n",
    "\n",
    "ezshow(dat1sil, col='yellow')\n",
    "ezshow(dat2sil, col='red')\n",
    "ezshow(dat3sil, col='orange')\n",
    "ezshow(dat4sil, col='green')\n",
    "ezshow(dat5sil, col='blue')\n",
    "ezshow(dat6sil, col='magenta')\n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')\n",
    "ezshow(dat5, col='blue')\n",
    "ezshow(dat6, col='magenta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_target = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# usesiren = False; first_omega_0=20; sigmac = 10;\n",
    "usesiren = True; first_omega_0=20; sigmac = 10;\n",
    "model = Siren(first_omega_0=first_omega_0, usesiren = usesiren, sigmac = sigmac).to(device); \n",
    "bmodel = Siren(first_omega_0=first_omega_0, usesiren = usesiren, sigmac = sigmac).to(device); \n",
    "# model.load_state('models/state_start.tar');\n",
    "my_loss = 'sinkhorn_large_reg';\n",
    "# %prun \n",
    "model, losses, separate_losses, lrs, n_subs = learn_trajectory(z_target, my_loss=my_loss,n_iters = 3000,n_subsample=500, model=model, bmodel=bmodel, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st.gpu_usage()\n",
    "# z_target.shape\n",
    "# z_target = ImageDataset.normalize_samples(torch.stack((dat2, dat1)).to(device));\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# z_target = ImageDataset.normalize_samples(torch.stack((dat2, dat1)).to(device));\n",
    "# model = FfjordModel().to(device); model.load_state('models/state_start.tar'); # print(next(model.parameters()).is_cuda)\n",
    "# my_loss = 'sinkhorn_large_reg';\n",
    "myln = my_loss+'_0';\n",
    "st.save_trajectory(model,z_target[:,1:4000,:],myln, savedir='imgs', nsteps=20, memory=0.01, n=500,dpiv=400)\n",
    "st.gpu_usage()\n",
    "st.trajectory_to_video(myln, savedir='imgs', mp4_fn='transform.mp4')\n",
    "\n",
    "# integration_times = torch.linspace(0,z_target.shape[0]-1,2).to(device);\n",
    "# model(z_target[1,:,:], integration_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=15;end=20000;\n",
    "plt.plot(losses[start:end]); \n",
    "# plt.plot(separate_losses[0,start:end],'g'); \n",
    "# plt.plot(separate_losses[1,start:end],'r'); \n",
    "# plt.plot(separate_losses[2,start:end]); \n",
    "# plt.plot(separate_losses[3,start:end]*.01,'r'); \n",
    "# plt.plot(separate_losses[4,start:end]*10,'b'); \n",
    "# plt.plot(separate_losses[5,start:end]); \n",
    "# plt.plot(separate_losses[6,start:end]);\n",
    "plt.savefig(os.path.join('./', f\"viz_loss.jpg\"),dpi=400); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig,(ax1,ax2))=plt.subplots(2,1)\n",
    "ax1.plot(n_subs[start:end],'r'); ax1.set_ylabel('n_sub')\n",
    "ax2.plot(lrs[start:end],'g'); ax2.set_ylabel('lr') \n",
    "plt.savefig(os.path.join('./', f\"viz_stat.jpg\"),dpi=400); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() \n",
    "st.gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'cat1.png'\n",
    "# # name = 'butterfly.jpg'\n",
    "img = cv.imread(name, cv.IMREAD_UNCHANGED);\n",
    "imggray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "print(img.shape)\n",
    "print(imggray.shape)\n",
    "\n",
    "edges = cv.Canny(img,50,200)\n",
    "# print(img.min(),img.max())\n",
    "# print(edges.min(),edges.max())\n",
    "plt.imshow(imggray);plt.show()\n",
    "plt.imshow(img);plt.show()\n",
    "plt.imshow(edges);plt.show()\n",
    "# i2 = img.copy()\n",
    "\n",
    "# img = cv.imread(name);\n",
    "# img[img<.8*255]=0; \n",
    "# # img/=img.max()\n",
    "# img=img.astype('float')\n",
    "# img/=img.max()\n",
    "# img.shape\n",
    "\n",
    "print(img.min(),img.max())\n",
    "print(imggray.min(),imggray.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test what weights are given to what frequencies in the first layer\n",
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "    pdat = param.data;\n",
    "    break;    \n",
    "pmags = torch.norm(param.data,p=2,dim=0);\n",
    "freqs = model.time_deriv_func.imap.B;\n",
    "nf = freqs.shape[0];\n",
    "nd = (pmags.shape[0]-2*nf)\n",
    "\n",
    "fmags = torch.norm(freqs,p=2,dim=1);\n",
    "xyfreqs = torch.cat([fmags, fmags],dim=0);\n",
    "print(xyfreqs.size())\n",
    "\n",
    "plt.plot(xyfreqs.cpu().numpy(), pmags[0:(nf*2)].cpu().numpy(),'.')\n",
    "plt.plot(np.zeros(nd), pmags[(nf*2):].cpu().numpy(),'.')\n",
    "plt.savefig(os.path.join('./', f\"viz_freqs.jpg\"),dpi=400); \n",
    "# # freqs\n",
    "# # fmags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize ending sinkhorn costs as gradient on point clouds\n",
    "# z_target = ImageDataset.normalize_samples(torch.stack((dat1,dat4)).to(device));\n",
    "T = z_target.shape[0];\n",
    "\n",
    "z_t = model(z_target[0,:,:], integration_times = torch.linspace(0,T-1,T).to(device),reverse=False);\n",
    "z_t_b = model(z_target[T-1,:,:], integration_times = torch.linspace(0,T-1,T).to(device),reverse=True);\n",
    "forward = z_t[T-1,:,:].cpu().detach().numpy();\n",
    "backward = z_t_b[T-1,:,:].cpu().detach().numpy();\n",
    "\n",
    "my_loss_f = SamplesLoss(\"sinkhorn\", p=2, blur=0.01);\n",
    "loss_f = my_loss_f(z_target[T-1,:,:], z_t[T-1,:,:])\n",
    "loss_b = my_loss_f(z_target[0,:,:], z_t_b[T-1,:,:])\n",
    "\n",
    "graddirs_f = torch.autograd.grad(loss_f, z_t)[0][T-1,:,:]\n",
    "graddirs_b = torch.autograd.grad(loss_b, z_t_b)[0][T-1,:,:]\n",
    "\n",
    "pos_f = z_t.cpu().detach().numpy()\n",
    "pos_b = z_t_b.cpu().detach().numpy()\n",
    "dirs_f = graddirs_f.cpu().detach().numpy()\n",
    "dirs_b = graddirs_b.cpu().detach().numpy()\n",
    "\n",
    "import os\n",
    "plt.axis('equal')\n",
    "plt.scatter(pos_b[0,:,0], pos_b[0,:,1], s=10, alpha=.5, linewidths=0, c='green', edgecolors='black')\n",
    "plt.scatter(forward[:,0], forward[:,1], s=10, alpha=.5, linewidths=0, c='red', edgecolors='black')\n",
    "plt.quiver(pos_f[T-1,:,0], pos_f[T-1,:,1], dirs_f[:,0], dirs_f[:,1],scale=.0001)\n",
    "plt.savefig(os.path.join('./', f\"viz_backward.jpg\"),dpi=400); plt.clf()\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.scatter(pos_f[0,:,0], pos_f[0,:,1], s=10, alpha=.5, linewidths=0, c='green', edgecolors='black')\n",
    "plt.scatter(backward[:,0], backward[:,1], s=10, alpha=.5, linewidths=0, c='red', edgecolors='black')\n",
    "plt.quiver(pos_b[T-1,:,0], pos_b[T-1,:,1], dirs_b[:,0], dirs_b[:,1],scale=.0001)\n",
    "plt.savefig(os.path.join('./', f\"viz_forward.jpg\"),dpi=400); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trying other shapes\n",
    "\n",
    "square = np.zeros([20,20])\n",
    "square[6:14,:8] = 1\n",
    "\n",
    "two_square = np.zeros([20,20])\n",
    "two_square[:5,14:] = 1\n",
    "two_square[15:,14:] = 1\n",
    "\n",
    "\n",
    "annulus = import_img('annulus.png')\n",
    "circle = 255-import_img('circle.jpeg')\n",
    "\n",
    "dset = ImageDataset(img=square)\n",
    "dset1 = ImageDataset(img=two_square)\n",
    "\n",
    "n = 500\n",
    "dat = dset.sample(n)\n",
    "dat1 = dset1.sample(n)\n",
    "plt.scatter(dat.detach().numpy()[:,0],dat.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='green')\n",
    "plt.scatter(dat1.detach().numpy()[:,0],dat1.detach().numpy()[:,1],s=2.3, alpha=0.1, linewidths=5,c='red')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make half moon dataset\n",
    "import sklearn.datasets\n",
    "\n",
    "moons, labels = sklearn.datasets.make_moons(n,noise=.1) #generates two half moons\n",
    "mask = (labels == 0)\n",
    "one_moon = moons[mask,:] # only keep one moon\n",
    "\n",
    "def rot_mat(theta0):\n",
    "    #computes rotation matrix of angle theta\n",
    "    return np.array([[np.cos(theta0),-np.sin(theta0)],[np.sin(theta0),np.cos(theta0)]])\n",
    "\n",
    "theta0 = np.pi/2\n",
    "theta1 = np.pi\n",
    "\n",
    "rot0 = rot_mat(theta0)\n",
    "rot1 = rot_mat(theta1)\n",
    "\n",
    "# apply rotation to the moon\n",
    "one_moon_rot0 = np.dot(one_moon,rot0)\n",
    "one_moon_rot1 = np.dot(one_moon,rot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize rotated moons\n",
    "\n",
    "plt.scatter(one_moon[:,0],one_moon[:,1], color='blue')\n",
    "plt.scatter(one_moon_rot0[:,0],one_moon_rot0[:,1], color='orange')\n",
    "plt.scatter(one_moon_rot1[:,0],one_moon_rot1[:,1], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with three timesteps\n",
    "\n",
    "dat = torch.tensor(one_moon,dtype=torch.float)\n",
    "dat0 = torch.tensor(one_moon_rot0,dtype=torch.float)\n",
    "dat1 = torch.tensor(one_moon_rot1,dtype=torch.float)\n",
    "\n",
    "dat_tuple = (dat,dat0,dat1)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for my_loss in ['sinkhorn_large_reg','sinkhorn_small_reg','energy_dist']:\n",
    "    model = learn_trajectory(z_target, my_loss=my_loss,n_batch=500)\n",
    "    save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "    trajectory_to_video(my_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with two timesteps\n",
    "\n",
    "\n",
    "dat_tuple = (dat,dat0)\n",
    "z_target = torch.stack(dat_tuple).to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for my_loss in ['sinkhorn_large_reg','sinkhorn_small_reg','energy_dist']:\n",
    "    model = learn_trajectory(z_target, my_loss=my_loss,n_batch=500)\n",
    "    save_trajectory(model,z_target,my_loss, savedir='imgs', nsteps=101, memory=0.01, n=1000)\n",
    "    trajectory_to_video(my_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
