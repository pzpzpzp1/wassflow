{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import pdb, time, math, numpy as np, gc, importlib, torch, os, cv2 as cv, ODEModel, matplotlib\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F \n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torchdiffeq import odeint_adjoint as odeint \n",
    "from geomloss import SamplesLoss\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import Utils, LearnVelTraj\n",
    "importlib.reload(Utils)\n",
    "from Utils import InputMapping, BoundingBox, ImageDataset, SaveTrajectory, ezshow, SaveTrajectory as st, MiscTransforms\n",
    "importlib.reload(ODEModel)\n",
    "from ODEModel import velocMLP, FfjordModel\n",
    "importlib.reload(LearnVelTraj);\n",
    "from LearnVelTraj import learn_vel_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-40167b0cd115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mxt_trajs_OT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cubic_OT_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n\u001b[0m\u001b[1;32m     25\u001b[0m                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n\u001b[1;32m     26\u001b[0m st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render_tight',\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ## TRAIN halloween ish. Concatenated OT maps only.\n",
    "f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 10000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='red')\n",
    "ezshow(dat2, col='yellow')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='black')\n",
    "\n",
    "outfolder = \"results/experiment_spook_cubic_OT/\"\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "\n",
    "xt_trajs_OT = st.get_cubic_OT_trajectory(keyframes, nsteps=20, n=2000)\n",
    "\n",
    "st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "                       dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n",
    "st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render_tight',\n",
    "                       dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False,tightBB=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN FISH234: Use OT cubic splines\n",
    "# f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "# f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_fish234_OT_cubic/\"\n",
    "\n",
    "# xt_trajs_OT = st.get_cubic_OT_trajectory(keyframes, nsteps=20, n=2000)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='cubic_OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='cubic_OT_render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False,tightBB=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. Concatenated OT maps only.\n",
    "# # f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# # f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# # f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# # f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# # n_inner = 10000;\n",
    "# # n_sil = 10000 - n_inner;\n",
    "# # dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# # dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# # dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# # dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# # ezshow(dat1, col='red')\n",
    "# # ezshow(dat2, col='yellow')\n",
    "# # ezshow(dat3, col='orange')\n",
    "# # ezshow(dat4, col='black')\n",
    "\n",
    "# # outfolder = \"results/experiment_spook_OT/\"\n",
    "\n",
    "# # keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# # xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=2000, ot_type=2)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False,tightBB=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN halloween ish. jerk .01, polar .1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_polar/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. jerk .01, radial .1\n",
    "# # f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# # f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# # f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# # f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# # n_inner = 10000;\n",
    "# # n_sil = 10000 - n_inner;\n",
    "# # dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# # dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# # dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# # dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# # ezshow(dat1, col='red')\n",
    "# # ezshow(dat2, col='yellow')\n",
    "# # ezshow(dat3, col='orange')\n",
    "# # ezshow(dat4, col='black')\n",
    "\n",
    "# # keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# # model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# # outfolder = \"results/experiment_spook_radial/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# # xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "# #                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "# #                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: noreg. sigma=7\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 7, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_noreg_sigma7/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: noreg. sigma=5\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 5, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_noreg_sigma5/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. div 1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_div1/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. rigid 2\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_rigid/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. curl on trajectory .1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_curlmean_p1/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. accel = 1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_accel_1/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. accel = 5\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_accel_5/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # # ## TRAIN carcination. jerk=.01. seems to look fine. not really going for a point here. but it looks cool enough i guess.\n",
    "# # f1 = ImageDataset('frames/lobster.jpg',noise_std=0,thresh=.50,binary=False); \n",
    "# # f2 = ImageDataset('frames/crab.jpg',noise_std=0); \n",
    "\n",
    "# # n_inner = 10000;\n",
    "# # n_sil = 10000 - n_inner;\n",
    "# # dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1.7, -1], center = [0,0], rotate = 0),0); \n",
    "# # dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1], center = [.9,0], rotate = -np.pi/2),0); \n",
    "\n",
    "# # ezshow(dat1, col='red')\n",
    "# # ezshow(dat2, col='blue')\n",
    "# # plt.axis('equal')\n",
    "\n",
    "# # keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# # model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# # outfolder = \"results/experiment_carcinization_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "# # xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "# #                        nsteps=40, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=10, cycle=False, lw=0, contrast=2, Nrbf = 100000, keyframes=False, tightBB=True)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "# #                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # after running rect_base and rect_slight_div, run this to get areas.\n",
    "# points = xt_trajs_1[0];\n",
    "# areas = np.zeros(points.shape[2])\n",
    "# for i in range(points.shape[2]):\n",
    "#     chull = scipy.spatial.ConvexHull(points[:,:,i])\n",
    "#     areas[i] = chull.volume\n",
    "# areas1=areas\n",
    "\n",
    "# points = xt_trajs_2[0];\n",
    "# areas = np.zeros(points.shape[2])\n",
    "# for i in range(points.shape[2]):\n",
    "#     chull = scipy.spatial.ConvexHull(points[:,:,i])\n",
    "#     areas[i] = chull.volume\n",
    "# areas2=areas\n",
    "\n",
    "# print(areas1[-1]-areas1[0]) \n",
    "# print(areas1.max()/areas1[0]) \n",
    "\n",
    "# print(areas2[-1]-areas2[0]) \n",
    "# print(areas2.max()/areas2[0]) \n",
    "\n",
    "# plt.plot(areas1/areas3[0],'r')\n",
    "# plt.plot(areas2/areas3[0],'g')\n",
    "\n",
    "# np.savetxt('results/outcache/areas1.txt', areas1)\n",
    "# np.savetxt('results/outcache/areas2.txt', areas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # ## TRAIN rectangles. KE=.1, div=1\n",
    "# n_inner = 10000;\n",
    "# dat1 = torch.rand(n_inner,2)-.5\n",
    "# dat2 = torch.rand(n_inner,2)-.5\n",
    "# dat2[:,0]*=3;dat2[:,1]/=3;\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_rects_slight_div/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=40, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)\n",
    "# xt_trajs_2 = xt_trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # ## TRAIN rectangles. KE=.1, div=0\n",
    "# # optimal transport from (1,1) square to (.33,3) rectangle should result in an area increase of 33.3% at the middle of the trajectory.\n",
    "# n_inner = 10000;\n",
    "# dat1 = torch.rand(n_inner,2)-.5\n",
    "# dat2 = torch.rand(n_inner,2)-.5\n",
    "# dat2[:,0]*=3;dat2[:,1]/=3;\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_rects_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=40, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)\n",
    "# xt_trajs_1 = xt_trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # ## TRAIN bars. KE=.01, rigid=10\n",
    "# f1 = ImageDataset('frames/square.png',noise_std=0); \n",
    "# rotate = torch.tensor(.3)\n",
    "# s, c = (torch.sin(rotate), torch.cos(rotate))\n",
    "# rot = torch.stack([torch.stack([c, -s]), torch.stack([s, c])])\n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, .1]),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, -.1]),0); \n",
    "# dat1 = dat1 @ rot\n",
    "# dat2 = dat2 @ rot.t()\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_bars_more_rigid/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "# #                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN bars. KE=.01, rigid=1\n",
    "# f1 = ImageDataset('frames/square.png',noise_std=0); \n",
    "# rotate = torch.tensor(.3)\n",
    "# s, c = (torch.sin(rotate), torch.cos(rotate))\n",
    "# rot = torch.stack([torch.stack([c, -s]), torch.stack([s, c])])\n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, .1]),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, -.1]),0); \n",
    "# dat1 = dat1 @ rot\n",
    "# dat2 = dat2 @ rot.t()\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_bars_rigid/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN bars. KE=.01\n",
    "# f1 = ImageDataset('frames/square.png',noise_std=0); \n",
    "# rotate = torch.tensor(.3)\n",
    "# s, c = (torch.sin(rotate), torch.cos(rotate))\n",
    "# rot = torch.stack([torch.stack([c, -s]), torch.stack([s, c])])\n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, .1]),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, -.1]),0); \n",
    "# dat1 = dat1 @ rot\n",
    "# dat2 = dat2 @ rot.t()\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_bars_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "# #                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000,keyframes=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # horse down to horse up - jerk = .01\n",
    "# im1 = ImageDataset('frames/horse1.jpg'); \n",
    "# im2 = ImageDataset('frames/horse2.jpg'); \n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d1 = im1.sample(n_inner, n_sil, center = [1, .5]); \n",
    "# d2 = im2.sample(n_inner, n_sil, center = [1, .5], scale=[-1, -1]); \n",
    "# dat1 = torch.cat(d1,0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_horseup_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=2000, ot_type=2)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=2, keyframes=False, Nrbf = 100000)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=2, keyframes=False, Nrbf = 100000, Nqvr=1, showVelocity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # horse character to horse - jerk = .01\n",
    "im1 = ImageDataset('frames/horse_charac.jpg'); \n",
    "im2 = ImageDataset('frames/horse.jpg'); \n",
    "\n",
    "n_inner = 7000;\n",
    "n_sil = 10000 - n_inner;\n",
    "d1 = im1.sample(n_inner, n_sil, center = [1, .5]); \n",
    "d2 = im2.sample(n_inner, n_sil, center = [1, .5], scale=[-1, -1]); \n",
    "\n",
    "dat1 = torch.cat(d1,0)\n",
    "dat2 = torch.cat(d2,0)\n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_horse_base/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000)\n",
    "\n",
    "xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=2000, ot_type=2)\n",
    "st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "                       dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000, Nqvr=1, showVelocity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # horse character to horse - jerk = .01\n",
    "# generate points\n",
    "im1 = ImageDataset('frames/horse_charac.jpg'); \n",
    "im2 = ImageDataset('frames/horse.jpg'); \n",
    "\n",
    "n_inner = 7000;\n",
    "n_sil = 10000 - n_inner;\n",
    "d1 = im1.sample(n_inner, n_sil, center = [1, .5]); \n",
    "d2 = im2.sample(n_inner, n_sil, center = [1, .5], scale=[-1, -1]); \n",
    "\n",
    "dat1 = torch.cat(d1,0)\n",
    "dat2 = torch.cat(d2,0)\n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_horse_base/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=10000)\n",
    "np.savetxt(outfolder+'xt_trajs.txt', torch.cat((torch.tensor(xt_trajs[0].shape), xt_trajs[0].reshape(-1)),0))\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000)\n",
    "\n",
    "xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=10000, ot_type=2)\n",
    "np.savetxt(outfolder+'xt_trajs_OT.txt', torch.cat((torch.tensor(xt_trajs_OT[0].shape), xt_trajs_OT[0].reshape(-1)),0))\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000, Nqvr=1, showVelocity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BUTTERFLY->CAT->CATERPILLAR - KE = .01, radialke = .1\n",
    "# im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "# im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "# im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "# im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [0.05, -.5]); \n",
    "# d1a = im1.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d1b = im1b.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d6 = im6.sample(n_inner, n_sil, center = [2, -.3]); \n",
    "\n",
    "# dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# dat6 = torch.cat(d6,0)\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat6, col='magenta')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat6, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_BCC_radial/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=4000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=1, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BUTTERFLY->CAT->CATERPILLAR - base. KE = .01\n",
    "# im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "# im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "# im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "# im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [0.05, -.5]); \n",
    "# d1a = im1.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d1b = im1b.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d6 = im6.sample(n_inner, n_sil, center = [2, -.3]); \n",
    "\n",
    "# dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# dat6 = torch.cat(d6,0)\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat6, col='magenta')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat6, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_BCC_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=4000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=1, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN FISH234 cycle. Jerk=.01. signedcurl=.1 curl everywhere\n",
    "# f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "# f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_fish234_signedcurl_even/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=30, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN FISH234 cycle. Jerk=.01. signedcurl=.1 average curl\n",
    "# f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "# f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_fish234_signedcurl/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN FISH234 cycle. Jerk=.01.\n",
    "# f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "# f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_fish234/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## GENERATE CYCLIC BUTTERFLY->CAT->CATERPILLAR. enforce completely cyclic.\n",
    "# im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "# im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "# im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "# im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [1, -1.2]); \n",
    "# d1a = im1.sample(n_inner, n_sil, center = [0, .13]); \n",
    "# d1b = im1b.sample(n_inner, n_sil, center = [0, .13]); \n",
    "# d6 = im6.sample(n_inner, n_sil, center = [2, .15]); \n",
    "\n",
    "# dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# dat6 = torch.cat(d6,0)\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat6, col='magenta')\n",
    "\n",
    "# ## TRAIN CYCLIC BUTTERFLY->CAT->CATERPILLAR. .1 radial, .01 jerk\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat6, dat2, dat1)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 4, in_features=3, out_features=2, incrementalMask = True,  Tperiod = len(keyframes)-1).to(device)\n",
    "# outfolder = \"results/experiment_BCC_cyclic/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=True, lw=.5, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN umbrella. Jerk=.01. poor temporal consistency because of discretized ot registration.\n",
    "# f1 = ImageDataset('frames/birdflock_start.jpg',noise_std=0,thresh=.9,binary=False); \n",
    "# f2 = ImageDataset('frames/umbrella.jpg',noise_std=0,thresh=.9); \n",
    "# f3 = ImageDataset('frames/birdflock_end.jpg',noise_std=.1,thresh=1,binary=False); \n",
    "\n",
    "# # dat1 = torch.cat(f1.sample(1000, 0, scale = [1.5, -1.2], center = [-1.5, .125], rotate = 0),0); \n",
    "# # dat1 = torch.randn(1000,2); dat1[:,0]*=.5; dat1[:,1]*=.2; dat1[:,0]-=.6\n",
    "# dat2 = torch.randn(1000,2); dat2[:,0]*=.2; dat2[:,1]*=.1; dat2[:,0]-=.2; dat2[:,1]+=.1\n",
    "# dat1 = dat2.clone(); dat1[:,0]-=.5\n",
    "# dat3 = torch.cat(f2.sample(900, 100, scale = [1, -1.1], center = [.13, -.05], rotate = 0),0); \n",
    "# dat4 = torch.cat(f3.sample(1000, 0, scale = [2, -2], center = [.2, .2], rotate = 0),0); \n",
    "# dat5 = torch.randn(1000,2); dat5[:,0]*=.8; dat5[:,1]*=.8; dat5[:,1]+=.5\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='orange')\n",
    "# ezshow(dat3, col='red')\n",
    "# ezshow(dat4, col='blue')\n",
    "# # ezshow(dat5, col='green')\n",
    "\n",
    "# # keyframes = torch.stack((dat1, dat2, dat3, dat4, dat5)).to(device);\n",
    "# keyframes = torch.stack((dat1, dat2, dat3, dat4)).to(device);\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_umbrella_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = True, lr = 1e-4, scaling = .4, normalize=False)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=100)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_points',\n",
    "#                        dpiv=600, sigma=.01, knn=1, cycle=False, lw=.01, contrast=1, Nrbf = 0, keyframes=False, showVelocity=False, plotKeypoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, div=1, rig.1\n",
    "f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.11, .125], rotate = 0),0); \n",
    "dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.13, -.05], rotate = -np.pi*.375),0); \n",
    "dat3 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, -.2], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='blue')\n",
    "\n",
    "keyframes = torch.stack((dat1, dat2, dat3)).to(device);\n",
    "\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MMF_rigdiv/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=False)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=10, cycle=True, lw=0, contrast=3, Nrbf = 100000,keyframes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, \n",
    "# f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.2, .5], rotate = -np.pi/7),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 4, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_MF2_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=10, cycle=True, lw=0, contrast=3, Nrbf = 100000,keyframes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TRAIN MF. Jerk=.01\n",
    "# f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.11, .325], rotate = 0),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.13, .15], rotate = -np.pi*.375),0); \n",
    "# dat3 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='blue')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_MMF_base/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=10, cycle=True, lw=0, contrast=3, Nrbf = 100000,keyframes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## GENERATE FISH IMAGES\n",
    "f1 = ImageDataset('frames/fish1.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1.2, -1], center = [-.07, .9], rotate = -np.pi/2),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.9, 0], rotate = -np.pi),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.9], rotate = np.pi/2),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.9, 0], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN FISH1234 circle. Jerk=.01\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RENDER ABOVE\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 2, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle/\"\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN FISH1234 circle. Jerk=.01. rigid=.1, curl-pi=.1\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle_morecurl_andrigid/\"\n",
    "model.load_state(outfolder + 'models/state_0050.tar')\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=953, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 5e-5, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RENDER ABOVE\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 2, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle_morecurl_andrigid/\"\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "model.load_state(outfolder + 'models/state_0050.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True, lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, rigid=2\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MF2_rigid/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE MF IMAGES\n",
    "f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, rigid=2\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MF_rigid/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MF_base/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE FISH IMAGES\n",
    "f1 = ImageDataset('frames/fish1.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [-.7, .6], rotate = 0),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [.7, -.6], rotate = 0),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [1, -1.1], center = [.7, .6], rotate = 0),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [1, -1.1], center = [-.7, -.6], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN FISH1234. Jerk=.01, curl=3\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_min3curl/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENDER FISH1234. Jerk=.01, curl=3\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234_min3curl/\"\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN FISH1234. Jerk=.01, curl=1\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_mincurl/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN FISH1234. Jerk=.01\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENDER FISH1234\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 2, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234/\"\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE BUNCH OF IMAGES\n",
    "im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "im3 = ImageDataset('frames/circle.jpeg'); \n",
    "im4 = ImageDataset('frames/baldhead.jpeg'); \n",
    "im5 = ImageDataset('frames/square.png'); \n",
    "im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "n_inner = 7000;\n",
    "n_sil = 10000 - n_inner;\n",
    "d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [0.05, -.5]); \n",
    "d1a = im1.sample(n_inner, n_sil, center = [0, 0]); \n",
    "d1b = im1b.sample(n_inner, n_sil, center = [0, 0]); \n",
    "d3 = im3.sample(n_inner, n_sil, center = [1, .5]); \n",
    "d4 = im4.sample(n_inner, n_sil, center = [1, -.5]); \n",
    "d5 = im5.sample(n_inner, n_sil, center = [1.9, .3]); \n",
    "d6 = im6.sample(n_inner, n_sil, center = [2, -.3]); \n",
    "\n",
    "dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "dat2 = torch.cat(d2,0)\n",
    "dat3 = torch.cat(d3,0)\n",
    "dat4 = torch.cat(d4,0)\n",
    "dat5 = torch.cat(d5,0)\n",
    "dat6 = torch.cat(d6,0)\n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')\n",
    "ezshow(dat5, col='blue')\n",
    "ezshow(dat6, col='magenta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
